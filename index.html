<html lang="en">
<head>
    <title>Play</title>
    <style>
        html, body { height: 100%; margin: 0; overflow: hidden; font-family: "Courier New", monospace; }
        #c { width: 100%; height: 100%; display: block; }
        #overlay {
            position: absolute;
            z-index: 2;
            top: 0; left: 0;
            width: 100%; height: 100%;
            display: flex;
            align-items: center;
            justify-content: center;
            background: rgba(0, 0, 0, 0);
        }
        #overlay button {
            background: rgba(0, 0, 0, 0); border: 0;
            color: #808080; padding: 16px 20px;
            text-transform: uppercase; cursor: pointer;
			      font-family: "Courier New", monospace;
			      font-size: 60px;
        }
        #loading-screen {
            position: absolute;
            z-index: 3;
            top: 0; left: 0;
            width: 100%; height: 100%;
            display: none;
            align-items: center;
            justify-content: center;
            background: rgba(255, 255, 255, 0);
            color: #acacac;
            font-size: 60px;
            font-family: "Courier New", monospace;
        }
        #info {
            position: absolute; 
            top: 0px; 
            width: 100%;
            padding: 10px; 
            box-sizing: border-box;
            text-align: center; 
            user-select: none;
            pointer-events: none; 
            z-index: 1;
            color: #ffffff;
            font-size: 14px;
            white-space: nowrap;
            overflow: visible;
        }
    </style>
</head>
<body>
<canvas id="c"></canvas>
<div id="overlay"><button id="startButton">Play</button></div>
<div id="loading-screen">3</div>
<div id="speed-meter" style="position: fixed; bottom: 1rem; left: 1rem; background-color: rgba(0, 0, 0, 0.6); 
     color: #ffffff; padding: 0.5rem 1rem; border-radius: 0.5rem; font-family: monospace; 
     font-size: .75rem; display: none; align-items: center; z-index: 1000;">
  <span>NOISE: </span>
  <div style="margin-left: 0.5rem; width: 200px; height: 20px; background-color: rgba(50, 50, 50, 0.7); 
       border-radius: 10px; overflow: hidden; position: relative;">
    <div id="speed-fill" style="height: 100%; width: 0%; background-color: #00ff00; 
         transition: width 0.1s, background-color 0.3s;"></div>
    <span id="speed-text" style="position: absolute; left: 50%; top: 50%; transform: translate(-50%, -50%); 
          color: white; font-size: 0.75rem; text-shadow: 0 0 2px black;">0</span>
  </div>
</div>
<script type="module">
    import * as THREE from "https://threejsfundamentals.org/threejs/resources/threejs/r122/build/three.module.js";
    import { PointerLockControls } from 'https://cdn.jsdelivr.net/npm/three@0.122.0/examples/jsm/controls/PointerLockControls.js';
    import { CSS3DRenderer, CSS3DObject } from 'https://cdn.jsdelivr.net/npm/three@0.122.0/examples/jsm/renderers/CSS3DRenderer.js';
    import { GLTFLoader } from 'https://cdn.jsdelivr.net/npm/three@0.122.0/examples/jsm/loaders/GLTFLoader.js';
    import { DRACOLoader } from 'https://cdn.jsdelivr.net/npm/three@0.122.0/examples/jsm/loaders/DRACOLoader.js';
    import { Box3 } from 'https://threejsfundamentals.org/threejs/resources/threejs/r122/build/three.module.js';
    import { PositionalAudioHelper } from 'https://cdn.jsdelivr.net/npm/three@0.122.0/examples/jsm/helpers/PositionalAudioHelper.js';

    const startButton = document.getElementById('startButton');
    const loadingScreen = document.getElementById('loading-screen');
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();

    // Check the maximum number of audio channels supported
console.log("Maximum channels supported:", audioContext.destination.maxChannelCount);

// Create a variable to track if we're in stereo or quad mode
let isQuadSupported = audioContext.destination.maxChannelCount >= 4;

// Set up the appropriate number of channels
if (isQuadSupported) {
    // Original code path - use all available channels for quad
    audioContext.destination.channelCount = audioContext.destination.maxChannelCount;
    audioContext.destination.channelCountMode = "explicit";
    audioContext.destination.channelInterpretation = "discrete";
    console.log("Using quad audio output with", audioContext.destination.channelCount, "channels");
} else {
    // New code path - only 2 channels available, use stereo mode
    audioContext.destination.channelCount = 2;
    audioContext.destination.channelCountMode = "explicit";
    audioContext.destination.channelInterpretation = "speakers";
    console.log("Using stereo audio output with downmixing");
}

    let sceneReady = false;
  
    startButton.addEventListener('click', init);

  async function init() {
        document.getElementById("overlay").remove();
        loadingScreen.style.display = 'flex';
        document.getElementById('speed-meter').style.display = 'flex';
      
        // Start the loading countdown
        let countdown = 3;
        const countInterval = setInterval(() => {
            countdown--;
            loadingScreen.textContent = countdown;
            
            if (countdown <= 0) {
                clearInterval(countInterval);
                loadingScreen.textContent = "m@ke s0me n0ise";
                setTimeout(() => {
                    loadingScreen.textContent = "m@ke s0me no!se";
                    setTimeout(() => {
                        loadingScreen.textContent = "m@ke s0me N0ise";
                            setTimeout(() => {
                                loadingScreen.textContent = "m@ke s0me n0!se";
                                    setTimeout(() => {
                                        loadingScreen.textContent = "m@ke s0me n0ise";
                                            setTimeout (() => {
                                                loadingScreen.style.display = 'none';
                                            }, 200); // fifth message duration
                                    }, 70); // fourth message duration
                            }, 300); // third message duration
                    }, 80); // second message duration
                 }, 400); // first message duration
            }
        }, 1000);

      
       // Add gamepad listener
        window.addEventListener("gamepadconnected", (event) => {
        console.log("Gamepad connected:", event.gamepad);
      });

        window.addEventListener("gamepaddisconnected", (event) => {
        console.log("Gamepad disconnected:", event.gamepad);
      });
      
      //

        const canvas = document.getElementById("c");
        const renderer = new THREE.WebGLRenderer({ canvas });
        const cssRenderer = new CSS3DRenderer();
        cssRenderer.setSize(window.innerWidth, window.innerHeight);
        cssRenderer.domElement.style.position = 'absolute';
        cssRenderer.domElement.style.top = 0;
        document.body.appendChild(cssRenderer.domElement);

        function adjustForDisplayScaling() {
        // Get the current zoom level and device pixel ratio
        const devicePixelRatio = window.devicePixelRatio;
        
        console.log("Current device pixel ratio:", devicePixelRatio);
        
        // For high-resolution displays, adjust the renderer pixel ratio
        if (devicePixelRatio > 1.5) {
            // For high-DPI displays, use a custom pixel ratio
            renderer.setPixelRatio(1.0); // Force 1:1 pixel ratio
            console.log("High-DPI display detected, adjusting pixel ratio");
        } else {
            // For standard displays, use the device's pixel ratio
            renderer.setPixelRatio(devicePixelRatio);
        }
        
        // Update sizes based on the adjusted pixel ratio
        renderer.setSize(window.innerWidth, window.innerHeight);
        cssRenderer.setSize(window.innerWidth, window.innerHeight);
        
        // Update camera
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        }

        const clock = new THREE.Clock();
        const scene = new THREE.Scene();
        const cssScene = new THREE.Scene();

        const camera = new THREE.PerspectiveCamera(65, window.innerWidth / window.innerHeight, 1, 3500);
      //  camera.position.set(-2530, 30, 3000);  //for DEVELOPMENT
        camera.position.set(1550, 30, -700);  //for performance

        adjustForDisplayScaling();

        //Add the resize listener
        window.addEventListener('resize', adjustForDisplayScaling);

        if (window.visualViewport) {
            window.visualViewport.addEventListener('resize', adjustForDisplayScaling);
        }

        const controls = new PointerLockControls(camera, renderer.domElement);
        
        // Track pointer lock state
        let isPointerLocked = false;

        // Add event listeners for pointer lock changes
        document.addEventListener('pointerlockchange', onPointerLockChange);
        document.addEventListener('mozpointerlockchange', onPointerLockChange);
        document.addEventListener('webkitpointerlockchange', onPointerLockChange);

        function onPointerLockChange() {
            // Check if pointer is currently locked
            isPointerLocked = (
                document.pointerLockElement === renderer.domElement ||
                document.mozPointerLockElement === renderer.domElement ||
                document.webkitPointerLockElement === renderer.domElement
            );
            
            console.log('Pointer lock state changed:', isPointerLocked ? 'locked' : 'unlocked');
            
            // Update movement state based on pointer lock
            if (!isPointerLocked) {
                // Stop forward movement when pointer lock is exited
                move.forward = false;
            }
        }

        const listener = new THREE.AudioListener();
        const threeJsAudioContext = listener.context;
        camera.add(listener);

        document.addEventListener('click', () => controls.lock());
      
        const move = { forward: false, backward: false, left: false, right: false };

        document.addEventListener('keydown', (event) => {
            switch (event.code) {
                case 'ArrowUp': case 'KeyW': move.forward = true; break;
                case 'ArrowDown': case 'KeyS': move.backward = true; break;
                case 'ArrowLeft': case 'KeyA': move.left = true; break;
                case 'ArrowRight': case 'KeyD': move.right = true; break;
            }
        });

        document.addEventListener('keyup', (event) => {
            switch (event.code) {
                case 'ArrowUp': case 'KeyW': move.forward = false; break;
                case 'ArrowDown': case 'KeyS': move.backward = false; break;
                case 'ArrowLeft': case 'KeyA': move.left = false; break;
                case 'ArrowRight': case 'KeyD': move.right = false; break;
            }
        });

        // Generate random color for the GridHelper
        function getRandomColor() {
            const color = Math.floor(Math.random() * 0xffffff);
            return color;
        }
        const gridHelper = new THREE.GridHelper(12000, 40, 0xff43cd, 0xff43cd);
      //  scene.add(gridHelper);

        function generateRandomString(length) {
            const characters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
            let result = '';
            for (let i = 0; i < length; i++) {
                result += characters.charAt(Math.floor(Math.random() * characters.length));
            }
            return result;
        }
             
      const geometry = new THREE.BoxGeometry( 40, 200, 2830 ); 
        const material = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube = new THREE.Mesh( geometry, material ); 
        cube.position.set(-1330, 50, 40);
        cube.userData.collidable = true;
        scene.add( cube );
      
      const geometry2 = new THREE.BoxGeometry( 40, 200, 2920 ); 
        const material2 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube2 = new THREE.Mesh( geometry2, material2 ); 
        cube2.position.set(-1620, 50, -170);
        cube2.userData.collidable = true;
        scene.add( cube2 );
      
      const geometry3 = new THREE.BoxGeometry( 3420, 200, 300 ); 
        const material3 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube3 = new THREE.Mesh( geometry3, material3 ); 
        cube3.position.set(0, 50, -1610);
        cube3.userData.collidable = true;
        scene.add( cube3 );
      
      const geometry4 = new THREE.BoxGeometry( 2880, 200, 40 ); 
        const material4 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube4 = new THREE.Mesh( geometry4, material4 ); 
        cube4.position.set(100, 50, -1360);
        cube4.userData.collidable = true;
        scene.add( cube4 );
      
      const geometry5 = new THREE.BoxGeometry( 1145, 230, 200 ); 
        const material5 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube5 = new THREE.Mesh( geometry5, material5 ); 
        cube5.position.set(-1780, 70, 1530);
        cube5.userData.collidable = true;
        scene.add( cube5 );
      
     const geometry6 = new THREE.BoxGeometry( 100, 200, 6670 ); 
        const material6 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube6 = new THREE.Mesh( geometry6, material6 ); 
        cube6.position.set(1490, 50, 1960);
        cube6.userData.collidable = true;
        scene.add( cube6 );
    
        const geometry7 = new THREE.BoxGeometry( 100, 200, 9370 ); 
        const material7 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube7 = new THREE.Mesh( geometry7, material7 ); 
        cube7.position.set(1610, 50, 2000);
        cube7.userData.collidable = true;
        scene.add( cube7 );
      
        const geometry8 = new THREE.BoxGeometry( 100, 200, 200 ); 
        const material8 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube8 = new THREE.Mesh( geometry8, material8 ); 
        cube8.position.set(1540, 50, -350);
        cube8.userData.collidable = true;
        scene.add( cube8 );
      
        const geometry9 = new THREE.BoxGeometry( 1145, 230, 40 ); 
        const material9 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube9 = new THREE.Mesh( geometry9, material9 ); 
        cube9.position.set(-2180, 70, 1280);
        cube9.userData.collidable = true;
        scene.add( cube9 );
      
        const geometry10 = new THREE.BoxGeometry( 40, 230, 4100 ); 
        const material10 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube10 = new THREE.Mesh( geometry10, material10 ); 
        cube10.position.set(-2600, 70, 3200);
        cube10.userData.collidable = true;
        scene.add( cube10 );
      
        const geometry11 = new THREE.BoxGeometry( 40, 230, 3800 ); 
        const material11 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube11 = new THREE.Mesh( geometry11, material11 ); 
        cube11.position.set(-2340, 70, 3500);
        cube11.userData.collidable = true;
        scene.add( cube11 );
      
        const geometry12 = new THREE.BoxGeometry( 840, 230, 100 ); 
        const material12 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube12 = new THREE.Mesh( geometry12, material12 ); 
        cube12.position.set(-2475, 70, 5200);
        cube12.userData.collidable = true;
        scene.add( cube12 );      

        const geometry13 = new THREE.BoxGeometry( 200, 200, 600 ); 
        const material13 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube13 = new THREE.Mesh( geometry13, material13 ); 
        cube13.position.set(-2480, 50, 3200);
        cube13.userData.collidable = true;
        scene.add( cube13 ); 

        const geometry14 = new THREE.BoxGeometry( 1000, 1000, 1000 ); 
        const material14 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube14 = new THREE.Mesh( geometry14, material14 ); 
        cube14.position.set(-1500, 0, 1000);
        cube14.userData.collidable = true;
        scene.add( cube14 ); 

        const geometry15 = new THREE.BoxGeometry( 500, 500, 500 ); 
        const material15 = new THREE.MeshBasicMaterial( {color: 0x00ff00, transparent: true, opacity: 0} ); 
        const cube15 = new THREE.Mesh( geometry15, material15 ); 
        cube15.position.set(-2500, 0, 3200);
        cube15.userData.collidable = true;
        scene.add( cube15 ); 
      
      // Add bounding box 1
      const greenBoxBoundingBox = new THREE.Box3().setFromObject(cube);
      const greenBoxHelper = new THREE.BoxHelper(cube, 0xffff00);
//     scene.add(greenBoxHelper);
      
       // Add bounding box 2
      const redBoxBoundingBox = new THREE.Box3().setFromObject(cube2);
      const redBoxHelper = new THREE.BoxHelper(cube2, 0xff0000);
//      scene.add(redBoxHelper);
      
        // Add bounding box 3
      const boundingBox3 = new THREE.Box3().setFromObject(cube3);
      const boundingBox3Helper = new THREE.BoxHelper(cube3, 0xff0000);
  //    scene.add(boundingBox3Helper);
      
        // Add bounding box 4
      const boundingBox4 = new THREE.Box3().setFromObject(cube4);
      const boundingBox4Helper = new THREE.BoxHelper(cube4, 0xff0000);
//     scene.add(boundingBox4Helper);
      
        // Add bounding box 5
      const boundingBox5 = new THREE.Box3().setFromObject(cube5);
      const boundingBox5Helper = new THREE.BoxHelper(cube5, 0xff0000);
 //    scene.add(boundingBox5Helper);
      
       // Add bounding box 6
      const boundingBox6 = new THREE.Box3().setFromObject(cube6);
      const boundingBox6Helper = new THREE.BoxHelper(cube6, 0xff0000);
  //    scene.add(boundingBox6Helper);
      
      
      // Add bounding box 7
      const boundingBox7 = new THREE.Box3().setFromObject(cube7);
      const boundingBox7Helper = new THREE.BoxHelper(cube7, 0xff0000);
  //    scene.add(boundingBox7Helper);
      
       // Add bounding box 8
      const boundingBox8 = new THREE.Box3().setFromObject(cube8);
      const boundingBox8Helper = new THREE.BoxHelper(cube8, 0xff0000);
  //   scene.add(boundingBox8Helper);
      
         // Add bounding box 9
      const boundingBox9 = new THREE.Box3().setFromObject(cube9);
      const boundingBox9Helper = new THREE.BoxHelper(cube9, 0xff0000);
//     scene.add(boundingBox9Helper);
      
       // Add bounding box 10
      const boundingBox10 = new THREE.Box3().setFromObject(cube10);
      const boundingBox10Helper = new THREE.BoxHelper(cube10, 0xff0000);
 //    scene.add(boundingBox10Helper);
      
      // Add bounding box 11
      const boundingBox11 = new THREE.Box3().setFromObject(cube11);
      const boundingBox11Helper = new THREE.BoxHelper(cube11, 0xff0000);
  //   scene.add(boundingBox11Helper);
      
      
        // Add bounding box 12
      const boundingBox12 = new THREE.Box3().setFromObject(cube12);
      const boundingBox12Helper = new THREE.BoxHelper(cube12, 0xff0000);
  //   scene.add(boundingBox12Helper);

         // Add bounding box 13
      const boundingBox13 = new THREE.Box3().setFromObject(cube13);
      const boundingBox13Helper = new THREE.BoxHelper(cube13, 0xff0000);
  //   scene.add(boundingBox13Helper);

          // Add bounding box 14
          const boundingBox14 = new THREE.Box3().setFromObject(cube14);
      const boundingBox14Helper = new THREE.BoxHelper(cube14, 0xff0000);
     //  scene.add(boundingBox14Helper);
    
          // Add bounding box 15
         const boundingBox15 = new THREE.Box3().setFromObject(cube15);
      const boundingBox15Helper = new THREE.BoxHelper(cube15, 0xff0000);
   //    scene.add(boundingBox15Helper);

      // Add bounding box for the camera
      const cameraBoundingBox = new THREE.Box3();
      const cameraBoundingHelperGeometry = new THREE.BoxGeometry(5, 5, 5); 
      const cameraBoundingHelperMaterial = new THREE.MeshBasicMaterial({ color: 0xff0000, wireframe: true }); // Red wireframe
      const cameraBoundingHelper = new THREE.Mesh(cameraBoundingHelperGeometry, cameraBoundingHelperMaterial);
   //   scene.add(cameraBoundingHelper);

      function updateBoundingBoxes() {
          // Update camera bounding box position to match the camera
          const cameraPosition = camera.position.clone();
          cameraBoundingHelper.position.copy(cameraPosition);
          cameraBoundingBox.setFromObject(cameraBoundingHelper);
      }
      
      //load 3d model of bell with animation
        const loader = new GLTFLoader();
        loader.setPath('');
        let mixer;
      
        loader.load('bell-ascii.glb', function (gltf) {
            gltf.scene.position.set(-830, -125, 5450);
            gltf.scene.scale.set(1000, 75, 125);
            gltf.scene.rotation.set(0, 0, 0);
    //        scene.add(gltf.scene);
       
        mixer = new THREE.AnimationMixer(gltf.scene);
        
        gltf.animations.forEach((clip) => {
        const action = mixer.clipAction(clip);
        action.setEffectiveTimeScale(0); // 0.5 for half speed, 2.0 for double speed
        action.play();
          });
        });

        //load 3d model of bell with animation
        const firstBellLoader = new GLTFLoader();
        firstBellLoader.setPath('');
        let firstBellMixer;
      
 //       firstBellLoader.load('the_accumoli_bell_animated.glb', function (gltf) {
            firstBellLoader.load('bell4-compressed-inverted-blender.glb', function (gltf) {
            gltf.scene.position.set(-2500, -50, 3200);
            gltf.scene.scale.set(20, 20, 100);
            gltf.scene.rotation.set(0, 0, 0);
            scene.add(gltf.scene);
       
        firstBellMixer = new THREE.AnimationMixer(gltf.scene);
        
        gltf.animations.forEach((clip) => {
        const action = firstBellMixer.clipAction(clip);
        action.setEffectiveTimeScale(1); // 0.5 for half speed, 2.0 for double speed
        action.play();
          });

              // Initialize animation state as paused
              window.bellAnimationState = {
        isPlaying: false,   // Start in paused state
        hasCollided: false,
        canToggle: true,
        actions: [],
        soundsLoaded: false
    };
    
    // For each animation clip
    gltf.animations.forEach((clip) => {
        // Create the action
        const action = firstBellMixer.clipAction(clip);
        
        // Get the animation duration
        const duration = clip.duration;
        console.log(`Bell animation duration: ${duration} seconds`);
        
        // Set initial time to halfway through the animation
        const quarterwayPoint = 3 * duration / 4;
        
        // Set effective time scale to normal (will be paused later)
        action.setEffectiveTimeScale(1);
        
        // Start the action
        action.play();
        
        // Advance the mixer to the halfway point
        firstBellMixer.setTime(quarterwayPoint);
        
        // Now pause by setting timeScale to 0
        action.timeScale = 0;
        
        // Store the action for future resume
        window.bellAnimationState.actions.push({
            action: action,
            time: quarterwayPoint,
            timeScale: 1
        });
    });
    
    console.log("Bell animation initialized and paused");
    
});

    //load 3d model of glitchy bell
        const loaderGlitchyBell = new GLTFLoader();
        loaderGlitchyBell.setPath('');
        let mixer4;
      
        loaderGlitchyBell.load('glitchybellpink.glb', function (gltf) {
            gltf.scene.position.set(-200, 100, -1450);
            gltf.scene.scale.set(70, 70, 70);
            gltf.scene.rotation.set(Math.PI/4, Math.PI/4, Math.PI/2);
         //   scene.add(gltf.scene);
       
        mixer4 = new THREE.AnimationMixer(gltf.scene);
        
        gltf.animations.forEach((clip) => {
        const action = mixer4.clipAction(clip);
        action.setEffectiveTimeScale(1); // 0.5 for half speed, 2.0 for double speed
        action.play();
          });
        });

        let bell2Model;
        //load 3d model of bell2 with animation
        const loaderBell2 = new GLTFLoader();
        loaderBell2.setPath('');
        let mixer2;
      
        loaderBell2.load('bell-ascii-inverted.glb', function (gltf) {
            gltf.scene.position.set(-2430, 400, 3200);
            gltf.scene.scale.set(135, 150, 1000);
            gltf.scene.rotation.set(0, -1/41 * Math.PI, -Math.PI);
         //   scene.add(gltf.scene);
       //  bell2Model = gltf.scene; // don't add to scene at first

       
        mixer2 = new THREE.AnimationMixer(gltf.scene);
        
        gltf.animations.forEach((clip) => {
        const action = mixer2.clipAction(clip);
        action.setEffectiveTimeScale(0); // 0.5 for half speed, 2.0 for double speed
        action.play();
          });
        });

        const dracoLoader1 = new DRACOLoader();
        dracoLoader1.setDecoderPath('https://www.gstatic.com/draco/versioned/decoders/1.5.6/');

        //load 3d model of bell3 with animation
        const loaderBell3 = new GLTFLoader();
        loaderBell3.setDRACOLoader(dracoLoader1);
        loaderBell3.setPath('');
        let mixer3;
      
        loaderBell3.load('bell4-compressed-inverted.glb', function (gltf) {
            gltf.scene.position.set(-1500, -200, 800);
            gltf.scene.scale.set(100, 100, 100);
            gltf.scene.rotation.set(Math.PI/4, Math.PI/4, 0);
            scene.add(gltf.scene);
       
        mixer3 = new THREE.AnimationMixer(gltf.scene);
        
        gltf.animations.forEach((clip) => {
        const action = mixer3.clipAction(clip);
        action.setEffectiveTimeScale(1); // 0.5 for half speed, 2.0 for double speed
        action.play();
    });

// Initialize animation state as paused
window.bell3AnimationState = {
isPlaying: false,   // Start in paused state
hasCollided: false,
canToggle: true,
actions: [],
soundsLoaded: false
};

// For each animation clip
gltf.animations.forEach((clip) => {
// Create the action
const action = mixer3.clipAction(clip);

// Get the animation duration
const duration = clip.duration;
console.log(`Bell animation duration: ${duration} seconds`);

// Set initial time to halfway through the animation
const quarterwayPoint = 3 * duration / 4;

// Set effective time scale to normal (will be paused later)
action.setEffectiveTimeScale(1);

// Start the action
action.play();

// Advance the mixer to the halfway point
mixer3.setTime(quarterwayPoint);

// Now pause by setting timeScale to 0
action.timeScale = 0;

// Store the action for future resume
window.bell3AnimationState.actions.push({
action: action,
time: quarterwayPoint,
timeScale: 1
});
});

console.log("Bell animation initialized and paused");

});

   /*
            // Create a DRACOLoader instance
        const dracoLoader = new DRACOLoader();
        // Specify the path to the Draco decoder
        dracoLoader.setDecoderPath('https://www.gstatic.com/draco/versioned/decoders/1.5.6/');

        // Create GLTFLoader and attach DRACOLoader
        const loaderBell4 = new GLTFLoader();
        loaderBell4.setDRACOLoader(dracoLoader);
        loaderBell4.setPath('');

        let mixer4;

        loaderBell4.load('bell4-compressed.glb', function (gltf) {
            gltf.scene.position.set(0, -500, 5250);
            gltf.scene.scale.set(200, 200, 200);
            gltf.scene.rotation.set(0, 3*Math.PI/4, Math.PI/4);
       //     scene.add(gltf.scene);

            mixer4 = new THREE.AnimationMixer(gltf.scene);
            
            gltf.animations.forEach((clip) => {
                const action = mixer4.clipAction(clip);
                action.setEffectiveTimeScale(.8);
                action.play();
            });
        });
*/
        // dispose of the decoder when done
        // dracoLoader.dispose();

         //load 3d model of bell5 with animation
         const loaderBell5 = new GLTFLoader();
        loaderBell5.setPath('');
        let mixer5;
      
        loaderBell5.load('', function (gltf) {
            gltf.scene.position.set(1550, 0, 3250);
            gltf.scene.scale.set(100, 100, 100);
            gltf.scene.rotation.set(0, 0, 0);
            scene.add(gltf.scene);
       
        mixer5 = new THREE.AnimationMixer(gltf.scene);
        
        gltf.animations.forEach((clip) => {
        const action = mixer5.clipAction(clip);
        action.setEffectiveTimeScale(1); // 0.5 for half speed, 2.0 for double speed
        action.play();
          });
        });
  
        const light = new THREE.HemisphereLight(0xffffff, 0x444444, 6);
        scene.add(light);

// Define constants for iframe loading
const LOAD_DISTANCE = 2500;    // Distance at which iframes are loaded
const UNLOAD_DISTANCE = 2500;  // Distance at which iframes are unloaded

// Improved IframeLazyLoader class
class IframeLazyLoader {
    constructor(position, rotation, scale, srcUrl, dimensions = { width: '1000px', height: '1000px' }, options = { pointerEvents: 'none' }) {
        // Store position and other details for distance calculations
        this.position = new THREE.Vector3(position.x, position.y, position.z);
        this.rotation = rotation;
        this.scale = scale;
        this.srcUrl = srcUrl;
        this.dimensions = dimensions;
        this.options = options;
        this.isLoaded = false;
        
        // Create the iframe object
        this.iframeObject = this.createIframeObject(this.position, this.rotation, this.scale, this.srcUrl, this.dimensions, this.options);
    }
    
    createIframeObject(position, rotation, scale, srcUrl, dimensions, options) {
        // Create container div
        const iframeDiv = document.createElement('div');
        iframeDiv.style.width = dimensions.width;
        iframeDiv.style.height = dimensions.height;
        iframeDiv.style.pointerEvents = options.pointerEvents;
        iframeDiv.style.zIndex = '-1';
        
        // Create iframe element with initially blank src
        const iframe = document.createElement('iframe');
        iframe.src = 'about:blank';  // Start with blank page
        iframe.style.width = '100%';
        iframe.style.height = '100%';
        iframe.style.border = '0';
        iframe.style.pointerEvents = options.pointerEvents;  // Apply same pointer events to iframe
        
        // Set permissions
        iframe.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
        iframe.allowFullscreen = true;
        
        // Append iframe to container
        iframeDiv.appendChild(iframe);
        
        // Create 3D object and set position, rotation, scale
        const iframeObject = new CSS3DObject(iframeDiv);
        iframeObject.position.set(position.x, position.y, position.z);
        iframeObject.rotation.set(rotation[0], rotation[1], rotation[2]);
        iframeObject.scale.set(scale[0], scale[1], scale[2]);
        iframeObject.renderOrder = -1;
        
        // Store references to DOM elements
        this.div = iframeDiv;
        this.iframe = iframe;
        
        // Add to CSS scene
        cssScene.add(iframeObject);
        
        return iframeObject;
    }
    
    load() {
        if (!this.isLoaded && this.iframe) {
            console.log(`Loading iframe: ${this.srcUrl}`);
            
            // Special handling for interactive iframes
            if (this.options.pointerEvents === 'auto') {
                this.iframe.src = this.srcUrl;
                
                // Make sure the iframe is visible and active
                this.div.style.display = 'block';
                this.iframe.style.pointerEvents = 'auto';
                this.div.style.pointerEvents = 'auto';
            } else {
                // Normal loading for non-interactive iframes
                this.iframe.src = this.srcUrl;
            }
            
            this.isLoaded = true;
        }
    }
    
    unload() {
        if (this.isLoaded && this.iframe) {
            console.log(`Unloading iframe: ${this.srcUrl}`);
            this.iframe.src = 'about:blank';
            this.isLoaded = false;
        }
    }
    
    updateVisibility(camera) {
        const distance = camera.position.distanceTo(this.position);
        
        if (distance < LOAD_DISTANCE && !this.isLoaded) {
            this.load();
        } else if (distance > UNLOAD_DISTANCE && this.isLoaded) {
            this.unload();
        }
    }
}

// Function to create all iframes with proper lazy loading
function setupLazyLoadedIframes() {
    // Clear any existing iframe loaders
    window.iframeLoaders = [];
    
    // Create iframe loaders with appropriate settings
    const iframeConfigs = [
        // Format: [position, rotation, scale, url, dimensions]
        [
            { x: 1560, y: -165, z: -1506 }, 
            [0, Math.PI/2, 0], 
            [1.15, .33, 1], 
            'hydrainwebpage3.html',
            { width: '2000px', height: '2000px' }
        ],
        [
            { x: 1530, y: -165, z: -380 }, 
            [0, -Math.PI/2, 0], 
            [1, .33, 1], 
            'hydrainwebpage3.html',
            { width: '2000px', height: '2000px' }
        ],
        [
            { x: -2475, y: 30, z: 5250 }, 
            [0, Math.PI, 0], 
            [.2, .2, .2], 
            'index.html',
            { width: '1080px', height: '720px' },
            { pointerEvents: 'auto' }  // Enable pointer events for this iframe
        ],
        [
            { x: -73, y: 0, z: -1460 }, 
            [0, 0, 0], 
            [3.55, .33, 1], 
            'hydrainwebpage7.html',
            { width: '1000px', height: '1000px' }
        ],
        [
            { x: -1600, y: 0, z: -300 }, 
            [0, Math.PI/2, 0], 
            [3.2, .33, 1], 
            'hydrainwebpage6.html',
            { width: '1000px', height: '1000px' }
        ],
        [
            { x: 30, y: 0, z: -1380 }, 
            [0, Math.PI, 0], 
            [3, .33, 1], 
            'hydrainwebpage7.html',
            { width: '1000px', height: '1000px' }
        ],
        [
            { x: -1350, y: 0, z: 0 }, 
            [0, Math.PI/2, 0], 
            [3, .33, 1], 
            'hydrainwebpage6.html',
            { width: '1000px', height: '1000px' }
        ],
        [
            { x: -1850, y: 45, z: 1450 }, 
            [0, 0, 0], 
            [10, 2.4, 1], 
            'hydrainwebpage6.html',
            { width: '100px', height: '100px' }
        ],
        [
            { x: -2100, y: 45, z: 1300 }, 
            [0, 0, 0], 
            [10, 2.4, 1], 
            'hydrainwebpage6.html',
            { width: '100px', height: '100px' }
        ],
        [
            { x: -2600, y: 45, z: 3290 }, 
            [0, Math.PI/2, 0], 
            [8.2, .48, 1], 
            'hydrainwebpage6.html',
            { width: '500px', height: '500px' }
        ],
        [
            { x: -2350, y: 45, z: 3400 }, 
            [0, Math.PI/2, 0], 
            [7.8, .48, 1], 
            'hydrainwebpage6.html',
            { width: '500px', height: '500px' }
        ]
    ];
    
    // Create and store all loaders
    iframeConfigs.forEach(config => {
        const loader = new IframeLazyLoader(
            config[0],  // position
            config[1],  // rotation
            config[2],  // scale
            config[3],  // source URL
            config[4],  // dimensions
            config[5] || { pointerEvents: 'none' }  // options (default to no pointer events)
        );
        window.iframeLoaders.push(loader);
    });
    
    console.log(`Created ${window.iframeLoaders.length} lazy-loaded iframes`);
}

setupAudioInput();   
setupLazyLoadedIframes();
function createHydraIframe() {
  // Declare the global variable for this iframe object
  let hydraIframeObject6;
  
  // Create container div
  const additionalIframeDiv6 = document.createElement('div');
  additionalIframeDiv6.style.width = '1000px';
  additionalIframeDiv6.style.height = '1000px';
  additionalIframeDiv6.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv6.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe6 = document.createElement('iframe');
  additionalIframe6.src = 'hydrainwebpage2.html';
  additionalIframe6.style.width = '100%';
  additionalIframe6.style.height = '100%';
  additionalIframe6.style.border = '0';
  additionalIframe6.style.pointerEvents = 'none';

  // Set permissions
  additionalIframe6.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe6.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv6.appendChild(additionalIframe6);

  // Create 3D object and position it
  const additionalIframeObject6 = new CSS3DObject(additionalIframeDiv6);
  additionalIframeObject6.position.set(1560, 0, -885);
  additionalIframeObject6.rotation.set(0, -Math.PI/2, 0);
  additionalIframeObject6.scale.set(1.15, .33, 1);
  additionalIframeObject6.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject6 = additionalIframeObject6;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject6);
  
  // Return the created object
  return additionalIframeObject6;
}

function createHydraIframe2() {
  // Declare the global variable for this iframe object
  let hydraIframeObject5;
  
  // Create container div
  const additionalIframeDiv5 = document.createElement('div');
  additionalIframeDiv5.style.width = '1000px';
  additionalIframeDiv5.style.height = '1000px';
  additionalIframeDiv5.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv5.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe5 = document.createElement('iframe');
  additionalIframe5.src = 'hydrainwebpage2.html';
  additionalIframe5.style.width = '100%';
  additionalIframe5.style.height = '100%';
  additionalIframe5.style.border = '0';
  additionalIframe5.style.pointerEvents = 'none';

  // Set permissions
  additionalIframe5.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe5.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv5.appendChild(additionalIframe5);

  // Create 3D object and position it
  const additionalIframeObject5 = new CSS3DObject(additionalIframeDiv5);
  additionalIframeObject5.position.set(1530, 0, -880);
  additionalIframeObject5.rotation.set(0, -Math.PI/2, 0);
  additionalIframeObject5.scale.set(1, .33, 1);
  additionalIframeObject5.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject5 = additionalIframeObject5;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject5);
  
  // Return the created object
  return additionalIframeObject5;
}

function createHydraIframe3() {
  // Declare the global variable for this iframe object
  let hydraIframeObject7;
  
  // Create container div
  const additionalIframeDiv7 = document.createElement('div');
  additionalIframeDiv7.style.width = '1080px';
  additionalIframeDiv7.style.height = '720px';
  additionalIframeDiv7.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv7.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe7 = document.createElement('iframe');
  additionalIframe7.src = 'index.html';
  additionalIframe7.style.width = '100%';
  additionalIframe7.style.height = '100%';
  additionalIframe7.style.border = '0';
 // additionalIframe7.style.pointerEvents = 'none';

  // Set permissions
 // additionalIframe7.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe7.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv7.appendChild(additionalIframe7);

  // Create 3D object and position it
  const additionalIframeObject7 = new CSS3DObject(additionalIframeDiv7);
  additionalIframeObject7.position.set(-2750, 30, 7500);
  additionalIframeObject7.rotation.set(0, Math.PI, 0);
  additionalIframeObject7.scale.set(1, 1, 1);
  additionalIframeObject7.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject7 = additionalIframeObject7;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject7);
  
  // Return the created object
  return additionalIframeObject7;
}

function createHydraIframe4() {
  // Declare the global variable for this iframe object
  let hydraIframeObject3;
  
  // Create container div
  const additionalIframeDiv3 = document.createElement('div');
  additionalIframeDiv3.style.width = '1000px';
  additionalIframeDiv3.style.height = '1000px';
  additionalIframeDiv3.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv3.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe3 = document.createElement('iframe');
  additionalIframe3.src = 'hydrainwebpage2.html';
  additionalIframe3.style.width = '100%';
  additionalIframe3.style.height = '100%';
  additionalIframe3.style.border = '0';
  additionalIframe3.style.pointerEvents = 'none';

  // Set permissions
  additionalIframe3.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe3.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv3.appendChild(additionalIframe3);

  // Create 3D object and position it
  const additionalIframeObject3 = new CSS3DObject(additionalIframeDiv3);
  additionalIframeObject3.position.set(-73, 0, -1460);
  additionalIframeObject3.rotation.set(0, 0, 0);
  additionalIframeObject3.scale.set(3.55, .33, 1);
  additionalIframeObject3.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject3 = additionalIframeObject3;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject3);
  
  // Return the created object
  return additionalIframeObject3;
}

function createHydraIframe5() {
  // Declare the global variable for this iframe object
  let hydraIframeObject2;
  
  // Create container div
  const additionalIframeDiv2 = document.createElement('div');
  additionalIframeDiv2.style.width = '1000px';
  additionalIframeDiv2.style.height = '1000px';
  additionalIframeDiv2.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv2.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe2 = document.createElement('iframe');
  additionalIframe2.src = 'hydrainwebpage2.html';
  additionalIframe2.style.width = '100%';
  additionalIframe2.style.height = '100%';
  additionalIframe2.style.border = '0';
  additionalIframe2.style.pointerEvents = 'none';

  // Set permissions
  additionalIframe2.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe2.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv2.appendChild(additionalIframe2);

  // Create 3D object and position it
  const additionalIframeObject2 = new CSS3DObject(additionalIframeDiv2);
  additionalIframeObject2.position.set(-1600, 0, -300);
  additionalIframeObject2.rotation.set(0, Math.PI/2, 0);
  additionalIframeObject2.scale.set(3.2, .33, 1);
  additionalIframeObject2.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject2 = additionalIframeObject2;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject2);
  
  // Return the created object
  return additionalIframeObject2;
}

function createHydraIframe6() {
  // Declare the global variable for this iframe object
  let hydraIframeObject4;
  
  // Create container div
  const additionalIframeDiv4 = document.createElement('div');
  additionalIframeDiv4.style.width = '1000px';
  additionalIframeDiv4.style.height = '1000px';
  additionalIframeDiv4.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv4.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe4 = document.createElement('iframe');
  additionalIframe4.src = 'hydrainwebpage2.html';
  additionalIframe4.style.width = '100%';
  additionalIframe4.style.height = '100%';
  additionalIframe4.style.border = '0';
  additionalIframe4.style.pointerEvents = 'none';

  // Set permissions
  additionalIframe4.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe4.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv4.appendChild(additionalIframe4);

  // Create 3D object and position it
  const additionalIframeObject4 = new CSS3DObject(additionalIframeDiv4);
  additionalIframeObject4.position.set(150, 0, -1380);
  additionalIframeObject4.rotation.set(0, 0, 0);
  additionalIframeObject4.scale.set(3, .33, 1);
  additionalIframeObject4.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject4 = additionalIframeObject4;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject4);
  
  // Return the created object
  return additionalIframeObject4;
}

function createHydraIframe7() {
  // Declare the global variable for this iframe object
  let hydraIframeObject;
  
  // Create container div
  const additionalIframeDiv = document.createElement('div');
  additionalIframeDiv.style.width = '1000px';
  additionalIframeDiv.style.height = '1000px';
  additionalIframeDiv.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe = document.createElement('iframe');
  additionalIframe.src = 'hydrainwebpage2.html';
  additionalIframe.style.width = '100%';
  additionalIframe.style.height = '100%';
  additionalIframe.style.border = '0';
  additionalIframe.style.pointerEvents = 'none';

  // Set permissions
  additionalIframe.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv.appendChild(additionalIframe);

  // Create 3D object and position it
  const additionalIframeObject = new CSS3DObject(additionalIframeDiv);
  additionalIframeObject.position.set(-1350, 0, 0);
  additionalIframeObject.rotation.set(0, Math.PI/2, 0);
  additionalIframeObject.scale.set(3, .33, 1);
  additionalIframeObject.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject = additionalIframeObject;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject);
  
  // Return the created object
  return additionalIframeObject;
}

function createHydraIframe8() {
  // Declare the global variable for this iframe object
  let hydraIframeObject11;
  
  // Create container div
  const additionalIframeDiv11 = document.createElement('div');
  additionalIframeDiv11.style.width = '100px';
  additionalIframeDiv11.style.height = '100px';
  additionalIframeDiv11.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv11.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe11 = document.createElement('iframe');
  additionalIframe11.src = 'hydrainwebpage2.html';
  additionalIframe11.style.width = '100%';
  additionalIframe11.style.height = '100%';
  additionalIframe11.style.border = '0';
  additionalIframe11.style.pointerEvents = 'none';

  // Set permissions
  additionalIframe11.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe11.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv11.appendChild(additionalIframe11);

  // Create 3D object and position it
  const additionalIframeObject11 = new CSS3DObject(additionalIframeDiv11);
  additionalIframeObject11.position.set(-1850, 45, 1450);
  additionalIframeObject11.rotation.set(0, 0, 0);
  additionalIframeObject11.scale.set(10, 2.4, 1);
  additionalIframeObject11.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject11 = additionalIframeObject11;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject11);
  
  // Return the created object
  return additionalIframeObject11;
}

function createHydraIframe9() {
  // Declare the global variable for this iframe object
  let hydraIframeObject12;
  
  // Create container div
  const additionalIframeDiv12 = document.createElement('div');
  additionalIframeDiv12.style.width = '100px';
  additionalIframeDiv12.style.height = '100px';
  additionalIframeDiv12.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv12.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe12 = document.createElement('iframe');
  additionalIframe12.src = 'hydrainwebpage2.html';
  additionalIframe12.style.width = '100%';
  additionalIframe12.style.height = '100%';
  additionalIframe12.style.border = '0';
  additionalIframe12.style.pointerEvents = 'none';

  // Set permissions
  additionalIframe12.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe12.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv12.appendChild(additionalIframe12);

  // Create 3D object and position it
  const additionalIframeObject12 = new CSS3DObject(additionalIframeDiv12);
  additionalIframeObject12.position.set(-2100, 45, 1300);
  additionalIframeObject12.rotation.set(0, 0, 0);
  additionalIframeObject12.scale.set(10, 2.4, 1);
  additionalIframeObject12.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject12 = additionalIframeObject12;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject12);
  
  // Return the created object
  return additionalIframeObject12;
}

function createHydraIframe10() {
  // Declare the global variable for this iframe object
  let hydraIframeObject13;
  
  // Create container div
  const additionalIframeDiv13 = document.createElement('div');
  additionalIframeDiv13.style.width = '500px';
  additionalIframeDiv13.style.height = '500px';
  additionalIframeDiv13.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv13.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe13 = document.createElement('iframe');
  additionalIframe13.src = 'hydrainwebpage2.html';
  additionalIframe13.style.width = '100%';
  additionalIframe13.style.height = '100%';
  additionalIframe13.style.border = '0';
  additionalIframe13.style.pointerEvents = 'none';

  // Set permissions
  additionalIframe13.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe13.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv13.appendChild(additionalIframe13);

  // Create 3D object and position it
  const additionalIframeObject13 = new CSS3DObject(additionalIframeDiv13);
  additionalIframeObject13.position.set(-2600, 45, 3290);
  additionalIframeObject13.rotation.set(0, Math.PI/2, 0);
  additionalIframeObject13.scale.set(8, .48, 1);
  additionalIframeObject13.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject13 = additionalIframeObject13;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject13);
  
  // Return the created object
  return additionalIframeObject13;
}

function createHydraIframe11() {
  // Declare the global variable for this iframe object
  let hydraIframeObject14;
  
  // Create container div
  const additionalIframeDiv14 = document.createElement('div');
  additionalIframeDiv14.style.width = '500px';
  additionalIframeDiv14.style.height = '500px';
  additionalIframeDiv14.style.pointerEvents = 'none'; // Click-through
  additionalIframeDiv14.style.zIndex = '-1';

  // Create iframe element
  const additionalIframe14 = document.createElement('iframe');
  additionalIframe14.src = 'hydrainwebpage2.html';
  additionalIframe14.style.width = '100%';
  additionalIframe14.style.height = '100%';
  additionalIframe14.style.border = '0';
  additionalIframe14.style.pointerEvents = 'none';

  // Set permissions
  additionalIframe14.allow = 'accelerometer; display-capture; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; camera; microphone';
  additionalIframe14.allowFullscreen = true;
  
  // Append iframe to container
  additionalIframeDiv14.appendChild(additionalIframe14);

  // Create 3D object and position it
  const additionalIframeObject14 = new CSS3DObject(additionalIframeDiv14);
  additionalIframeObject14.position.set(-2350, 45, 3400);
  additionalIframeObject14.rotation.set(0, Math.PI/2, 0);
  additionalIframeObject14.scale.set(7.8, .48, 1);
  additionalIframeObject14.renderOrder = -1;
  
  // Assign to global variable
  hydraIframeObject14 = additionalIframeObject14;
  
  // Add to CSS scene
  cssScene.add(additionalIframeObject14);
  
  // Return the created object
  return additionalIframeObject14;
}

// Function to calculate gains based on listener position - FIRST SOURCE
function calculateChannelGains(listenerPos, sourcePos, controls) {
    // Calculate relative position of the source
    const relativePos = sourcePos.clone().sub(listenerPos);
    
    // Get the world quaternion of the camera
    const cameraWorldQuaternion = new THREE.Quaternion();
    controls.getObject().getWorldQuaternion(cameraWorldQuaternion);
    
    // Create an inverse quaternion manually
    const inverseQuaternion = cameraWorldQuaternion.clone();
    inverseQuaternion.conjugate();
    
    // Rotate the relative position
    const rotatedRelativePos = relativePos.clone();
    rotatedRelativePos.applyQuaternion(inverseQuaternion);
    
    // Calculate distance and base gain
    const distance = Math.sqrt(rotatedRelativePos.x * rotatedRelativePos.x + rotatedRelativePos.z * rotatedRelativePos.z);
    const maxDistance = 2500;
    const baseGain = Math.max(0, 1 - distance / maxDistance);

    // Calculate angle from camera's forward direction (z-axis)
    const angle = Math.atan2(rotatedRelativePos.x, rotatedRelativePos.z);
    
    // Distribute audio around the listener using normalized directional weights
    const backLeftGain = Math.max(0, Math.cos(angle + Math.PI/4));
    const backRightGain = Math.max(0, Math.cos(angle - Math.PI/4));
    const frontLeftGain = Math.max(0, Math.cos(angle + Math.PI*3/4));
    const frontRightGain = Math.max(0, Math.cos(angle - Math.PI*3/4));

    // Normalize the directional weights so they sum to 1
    const weights = [frontLeftGain, frontRightGain, backLeftGain, backRightGain];
    const totalWeight = weights.reduce((sum, weight) => sum + weight, 0);
    const normalizedWeights = weights.map(weight => weight / totalWeight);
    
    // Apply the base gain (distance-based attenuation) to all channels
    // This step preserves the distance-based volume changes
    return normalizedWeights.map(weight => weight * baseGain);
}

// Function to calculate gains for the second sound source
function calculateSecondChannelGains(listenerPos, sourcePos, controls) {
    // Calculate relative position of the source
    const relativePos = sourcePos.clone().sub(listenerPos);
    
    // Get the world quaternion of the camera
    const cameraWorldQuaternion = new THREE.Quaternion();
    controls.getObject().getWorldQuaternion(cameraWorldQuaternion);
    
    // Create an inverse quaternion manually
    const inverseQuaternion = cameraWorldQuaternion.clone();
    inverseQuaternion.conjugate();
    
    // Rotate the relative position
    const rotatedRelativePos = relativePos.clone();
    rotatedRelativePos.applyQuaternion(inverseQuaternion);
    
    // Calculate distance and base gain - different falloff for second source
    const distance = Math.sqrt(rotatedRelativePos.x * rotatedRelativePos.x + rotatedRelativePos.z * rotatedRelativePos.z);
    const maxDistance = 1200; // Different max distance for second source
    const baseGain = Math.max(0, 1 - distance / maxDistance);

    // Calculate angle from camera's forward direction (z-axis)
    const angle = Math.atan2(rotatedRelativePos.x, rotatedRelativePos.z);
    
    // Distribute audio around the listener using normalized directional weights
    const backLeftGain = Math.max(0, Math.cos(angle + Math.PI/4));
    const backRightGain = Math.max(0, Math.cos(angle - Math.PI/4));
    const frontLeftGain = Math.max(0, Math.cos(angle + Math.PI*3/4));
    const frontRightGain = Math.max(0, Math.cos(angle - Math.PI*3/4));

    // Normalize the directional weights so they sum to 1
    const weights = [frontLeftGain, frontRightGain, backLeftGain, backRightGain];
    const totalWeight = weights.reduce((sum, weight) => sum + weight, 0);
    const normalizedWeights = weights.map(weight => weight / totalWeight);
    
    // Apply the base gain (distance-based attenuation) to all channels
    // This step preserves the distance-based volume changes
    return normalizedWeights.map(weight => weight * baseGain);
}

// Function to calculate gains for the third sound source
function calculateThirdChannelGains(listenerPos, sourcePos, controls) {
    // Calculate relative position of the source
    const relativePos = sourcePos.clone().sub(listenerPos);
    
    // Get the world quaternion of the camera
    const cameraWorldQuaternion = new THREE.Quaternion();
    controls.getObject().getWorldQuaternion(cameraWorldQuaternion);
    
    // Create an inverse quaternion manually
    const inverseQuaternion = cameraWorldQuaternion.clone();
    inverseQuaternion.conjugate();
    
    // Rotate the relative position
    const rotatedRelativePos = relativePos.clone();
    rotatedRelativePos.applyQuaternion(inverseQuaternion);
    
    // Calculate distance and base gain - different falloff for third source
    const distance = Math.sqrt(rotatedRelativePos.x * rotatedRelativePos.x + rotatedRelativePos.z * rotatedRelativePos.z);
    const maxDistance = 2500; // Different max distance for second source
    const baseGain = Math.max(0, .1 - (distance / maxDistance)/10);

    // Calculate angle from camera's forward direction (z-axis)
    const angle = Math.atan2(rotatedRelativePos.x, rotatedRelativePos.z);
    
    // Distribute audio around the listener using normalized directional weights
    const backLeftGain = Math.max(0, Math.cos(angle + Math.PI/4));
    const backRightGain = Math.max(0, Math.cos(angle - Math.PI/4));
    const frontLeftGain = Math.max(0, Math.cos(angle + Math.PI*3/4));
    const frontRightGain = Math.max(0, Math.cos(angle - Math.PI*3/4));

    // Normalize the directional weights so they sum to 1
    const weights = [frontLeftGain, frontRightGain, backLeftGain, backRightGain];
    const totalWeight = weights.reduce((sum, weight) => sum + weight, 0);
    const normalizedWeights = weights.map(weight => weight / totalWeight);
    
    // Apply the base gain (distance-based attenuation) to all channels
    // This step preserves the distance-based volume changes
    return normalizedWeights.map(weight => weight * baseGain);
}

// Define the fixed 3D position for the first sound source
const soundSourcePosition = new THREE.Vector3(-2430, 50, 3300);

// Define the fixed 3D position for the second sound source
const secondSoundSourcePosition = new THREE.Vector3(-1450, 50, 1000);

// Define the fixed 3D position for the third sound source
const thirdSoundSourcePosition = new THREE.Vector3(-200, 50, -1450);

// Load and play sound at a fixed position
const audioLoader = new THREE.AudioLoader();
let sourceNode;
let channelGains = [];

// Create Channel Merger with the appropriate number of channels
const mergerChannels = isQuadSupported ? 4 : 2;
const merger = audioContext.createChannelMerger(mergerChannels);
merger.connect(audioContext.destination);

// Create a master gain for fading in/out
const masterGain = audioContext.createGain();
masterGain.gain.value = 0; // Start silent
masterGain.connect(audioContext.destination);

audioLoader.load('pulsar_2.mp3', function(buffer) {
    // Create a buffer source
    sourceNode = audioContext.createBufferSource();
    sourceNode.buffer = buffer;
    sourceNode.loop = true;
    
    const numChannels = buffer.numberOfChannels;
    console.log(`Audio file has ${numChannels} channels`);
    
    // Create individual gain nodes - use either 4 or 2 based on isQuadSupported
    const gainNodeCount = isQuadSupported ? 4 : 2;
    channelGains = []; // Clear the array to avoid duplicates if reloaded
    
    for (let i = 0; i < gainNodeCount; i++) {
        const gainNode = audioContext.createGain();
        gainNode.gain.value = 0.5; // Initial gain value
        channelGains.push(gainNode);
        
        // Connect each gain node to its corresponding merger input
        // Note: We're using the merger directly as in the original code
        gainNode.connect(merger, 0, i);
    }
    
    // For mono sources (most common case), we need to send the same signal to all channels
    if (numChannels === 1) {
        // Connect source directly to all gain nodes
        for (let i = 0; i < channelGains.length; i++) {
            sourceNode.connect(channelGains[i]);
        }
    } 
    // For stereo sources, handle differently based on quad support
    else if (numChannels === 2) {
        const splitter = audioContext.createChannelSplitter(2);
        sourceNode.connect(splitter);
        
        if (isQuadSupported) {
            // Quad mode - Left channel to front-left and back-left
            splitter.connect(channelGains[0], 0);
            splitter.connect(channelGains[2], 0);
            
            // Right channel to front-right and back-right
            splitter.connect(channelGains[1], 1);
            splitter.connect(channelGains[3], 1);
        } else {
            // Stereo mode - direct connections
            splitter.connect(channelGains[0], 0); // Left to left
            splitter.connect(channelGains[1], 1); // Right to right
        }
    }

    // Store the buffer but DON'T start playback immediately
    // Initialize audio state tracker
    window.audioState = {
        isPlaying: false,
        buffer: buffer,
        currentSource: sourceNode,
        lastStartTime: 0,
        playbackOffset: 0,
        duration: buffer.duration
    };
    
    // Set initial gain values and start update loop
    updateAudioGains();
});

// Function to update audio gains dynamically
function updateAudioGains() {
    if (!sourceNode) return;
    
    // Calculate positional gains - still get 4 values
    const posGains = calculateChannelGains(
        camera.position, 
        soundSourcePosition, 
        controls
    );

    if (isQuadSupported) {
        // Quad mode - apply gains directly to the 4 channels
        for (let i = 0; i < channelGains.length; i++) {
            if (channelGains[i]) {
                channelGains[i].gain.setTargetAtTime(
                    posGains[i], 
                    audioContext.currentTime, 
                    0.1
                );
            }
        }
    } else {
        // Stereo mode - downmix front/back to left/right
        // Mix front-left + back-left to left channel
        // Mix front-right + back-right to right channel
        if (channelGains[0]) {
            channelGains[0].gain.setTargetAtTime(
                posGains[0] + posGains[2], // mix front-left and back-left
                audioContext.currentTime,
                0.1
            );
        }
        
        if (channelGains[1]) {
            channelGains[1].gain.setTargetAtTime(
                posGains[1] + posGains[3], // mix front-right and back-right
                audioContext.currentTime,
                0.1
            );
        }
    }
    
    // Continue updating
    requestAnimationFrame(updateAudioGains);
}

// Create a second set of channel gains for the new sound source
let secondSourceNode;
let secondChannelGains = [];

// Load and play second sound at its fixed position
// Load and play second sound at its fixed position
audioLoader.load('pulsar_1.mp3', function(buffer) {
    // Create a buffer source for the second sound
    secondSourceNode = audioContext.createBufferSource();
    secondSourceNode.buffer = buffer;
    secondSourceNode.loop = true;
    
    // Create individual gain nodes - use either 4 or 2 based on isQuadSupported
    const gainNodeCount = isQuadSupported ? 4 : 2;
    
    for (let i = 0; i < gainNodeCount; i++) {
        const gainNode = audioContext.createGain();
        gainNode.gain.value = 0.5; // Start with audible gain to test
        secondChannelGains.push(gainNode);
        
        // Connect each gain node to its corresponding merger input
        gainNode.connect(merger, 0, i);
    }
    
    // For mono sources, we need to send the same signal to all channels
    const numChannels = buffer.numberOfChannels;
    console.log(`Second audio file has ${numChannels} channels`);
    
    if (numChannels === 1) {
        // Connect source directly to all gain nodes
        for (let i = 0; i < secondChannelGains.length; i++) {
            secondSourceNode.connect(secondChannelGains[i]);
        }
    } 
    // For stereo sources, handle differently based on quad support
    else if (numChannels === 2) {
        const splitter = audioContext.createChannelSplitter(2);
        secondSourceNode.connect(splitter);
        
        if (isQuadSupported) {
            // Quad mode - Left channel to front-left and back-left
            splitter.connect(secondChannelGains[0], 0);
            splitter.connect(secondChannelGains[2], 0);
            
            // Right channel to front-right and back-right
            splitter.connect(secondChannelGains[1], 1);
            splitter.connect(secondChannelGains[3], 1);
        } else {
            // Stereo mode - direct connections
            splitter.connect(secondChannelGains[0], 0); // Left to left
            splitter.connect(secondChannelGains[1], 1); // Right to right
        }
    }

    // Start playback
 //   secondSourceNode.start();
    
    // Set initial gain values and start update loop
    updateSecondAudioGains();
});

// Function to update second audio gains dynamically
function updateSecondAudioGains() {
    if (!secondSourceNode) return;
    
    // Calculate positional gains - still get 4 values
    const posGains = calculateSecondChannelGains(
        camera.position, 
        secondSoundSourcePosition, 
        controls
    );

    if (isQuadSupported) {
        // Quad mode - apply gains directly
        for (let i = 0; i < secondChannelGains.length; i++) {
            if (secondChannelGains[i]) {
                secondChannelGains[i].gain.setTargetAtTime(
                    posGains[i], 
                    audioContext.currentTime, 
                    0.1
                );
            }
        }
    } else {
        // Stereo mode - downmix
        if (secondChannelGains[0]) {
            secondChannelGains[0].gain.setTargetAtTime(
                posGains[0] + posGains[2], // mix front-left and back-left
                audioContext.currentTime,
                0.1
            );
        }
        
        if (secondChannelGains[1]) {
            secondChannelGains[1].gain.setTargetAtTime(
                posGains[1] + posGains[3], // mix front-right and back-right
                audioContext.currentTime,
                0.1
            );
        }
    }
    
    // Continue updating
    requestAnimationFrame(updateSecondAudioGains);
}

// Create a third set of channel gains
let thirdSourceNode;
let thirdChannelGains = [];

// Load and play second sound at its fixed position
// Load and play second sound at its fixed position
audioLoader.load('sax-air-noise.mp3', function(buffer) {
    // Create a buffer source for the second sound
    thirdSourceNode = audioContext.createBufferSource();
    thirdSourceNode.buffer = buffer;
    thirdSourceNode.loop = true;
    
    // Create individual gain nodes - use either 4 or 2 based on isQuadSupported
    const gainNodeCount = isQuadSupported ? 4 : 2;
    
    for (let i = 0; i < gainNodeCount; i++) {
        const gainNode = audioContext.createGain();
        gainNode.gain.value = 0.5; // Start with audible gain to test
        thirdChannelGains.push(gainNode);
        
        // Connect each gain node to its corresponding merger input
        gainNode.connect(merger, 0, i);
    }
    
    // For mono sources, we need to send the same signal to all channels
    const numChannels = buffer.numberOfChannels;
    console.log(`Third audio file has ${numChannels} channels`);
    
    if (numChannels === 1) {
        // Connect source directly to all gain nodes
        for (let i = 0; i < thirdChannelGains.length; i++) {
            thirdSourceNode.connect(thirdChannelGains[i]);
        }
    } 
    // For stereo sources, handle differently based on quad support
    else if (numChannels === 2) {
        const splitter = audioContext.createChannelSplitter(2);
        thirdSourceNode.connect(splitter);
        
        if (isQuadSupported) {
            // Quad mode - Left channel to front-left and back-left
            splitter.connect(thirdChannelGains[0], 0);
            splitter.connect(thirdChannelGains[2], 0);
            
            // Right channel to front-right and back-right
            splitter.connect(thirdChannelGains[1], 1);
            splitter.connect(thirdChannelGains[3], 1);
        } else {
            // Stereo mode - direct connections
            splitter.connect(thirdChannelGains[0], 0); // Left to left
            splitter.connect(thirdChannelGains[1], 1); // Right to right
        }
    }

    // Start playback
    thirdSourceNode.start();
    
    // Set initial gain values and start update loop
    updateThirdAudioGains();
});

// Function to update third audio gains dynamically
function updateThirdAudioGains() {
    if (!thirdSourceNode) return;
    
    // Calculate positional gains - still get 4 values
    const posGains = calculateThirdChannelGains(
        camera.position, 
        thirdSoundSourcePosition, 
        controls
    );

    if (isQuadSupported) {
        // Quad mode - apply gains directly
        for (let i = 0; i < thirdChannelGains.length; i++) {
            if (thirdChannelGains[i]) {
                thirdChannelGains[i].gain.setTargetAtTime(
                    posGains[i], 
                    audioContext.currentTime, 
                    0.1
                );
            }
        }
    } else {
        // Stereo mode - downmix
        if (thirdChannelGains[0]) {
            thirdChannelGains[0].gain.setTargetAtTime(
                posGains[0] + posGains[2], // mix front-left and back-left
                audioContext.currentTime,
                0.1
            );
        }
        
        if (thirdChannelGains[1]) {
            thirdChannelGains[1].gain.setTargetAtTime(
                posGains[1] + posGains[3], // mix front-right and back-right
                audioContext.currentTime,
                0.1
            );
        }
    }
    
    // Continue updating
    requestAnimationFrame(updateThirdAudioGains);
}

    function resizeRendererToDisplaySize(renderer) {
        const canvas = renderer.domElement;
        // Use the renderer's pixel ratio instead of window.devicePixelRatio
        const pixelRatio = renderer.getPixelRatio();
        const width = canvas.clientWidth * pixelRatio | 0;
        const height = canvas.clientHeight * pixelRatio | 0;
        const needResize = canvas.width !== width || canvas.height !== height;
        if (needResize) {
            // Don't override our custom pixel ratio setting
            renderer.setSize(width / pixelRatio, height / pixelRatio, false);
            cssRenderer.setSize(width / pixelRatio, height / pixelRatio);
        }
        return needResize;
    }
   
  
// Create the ABC text in top left corner
const abcDiv = document.createElement('div');
abcDiv.style.position = 'fixed';
abcDiv.style.top = '1rem';
abcDiv.style.left = '1rem';
abcDiv.style.backgroundColor = 'rgba(0, 0, 0, 0)';
abcDiv.style.color = 'white';
abcDiv.style.padding = '0.5rem 1rem';
abcDiv.style.borderRadius = '0.5rem';
abcDiv.style.fontFamily = 'monospace';
abcDiv.style.fontSize = '1.25rem';
abcDiv.innerHTML = 'CAM01 CHANNEL01';
document.body.appendChild(abcDiv);

// Create the clock div element
const clockDiv = document.createElement('div');
clockDiv.style.position = 'fixed';
clockDiv.style.top = '1rem';
clockDiv.style.right = '1rem';
clockDiv.style.backgroundColor = 'rgba(0, 0, 0, 0)';
clockDiv.style.color = 'white';
clockDiv.style.padding = '0.5rem 1rem';
clockDiv.style.whiteSpace = 'nowrap';
clockDiv.style.borderRadius = '0.5rem';
clockDiv.style.fontFamily = 'monospace';
clockDiv.style.fontSize = '1.25rem';
document.body.appendChild(clockDiv);

// Format function to ensure numbers are always two digits
const formatTime = (num) => num.toString().padStart(2, '0');

// Function to update the clock with current time and date
function updateClock() {
    const now = new Date();
    const hours = now.getHours();
    const minutes = now.getMinutes();
    const seconds = now.getSeconds();
    
    // Get date components
    const day = now.getDate();
    const month = now.getMonth() + 1; // getMonth() returns 0-11
    const year = now.getFullYear();
    
    // Display time and date
    clockDiv.textContent = `${formatTime(day)}-${formatTime(month)}-${year} ${formatTime(hours)}:${formatTime(minutes)}:${formatTime(seconds)}`;
}

// Update clock immediately and then every second
updateClock();
const clockInterval = setInterval(updateClock, 1000);

// Optional: Clear interval when no longer needed
// clearInterval(clockInterval);

// Create a chat container
const chatContainer = document.createElement('div');
chatContainer.style.position = 'fixed';
chatContainer.style.bottom = '20px';
chatContainer.style.right = '20px';
chatContainer.style.width = '300px';
chatContainer.style.maxHeight = '400px';
chatContainer.style.overflowY = 'auto';
chatContainer.style.backgroundColor = 'rgba(0, 0, 0, 0.7)';
chatContainer.style.borderRadius = '10px';
chatContainer.style.padding = '10px';
chatContainer.style.fontFamily = '"Courier New", monospace';
chatContainer.style.zIndex = '1000';
document.body.appendChild(chatContainer);

// Arrays of possible noise messages
const initialNoiseMessages = [
    "Did u hear that?",
    "Do you know which way is out??????",
    "Where r we lol",
    "um how do i move",
    "why is it so dark rn"
];

const laterNoiseMessages = [
    "Signal breach imminent",
    "Interference detected",
    "Data corruption warning",
    "Noise levels increasing",
    "Unusual patterns detected",
    "Decrypting signal...",
    "U all still there?",
    "Anybody?",
    "Did u hear it that time?",
    "Connection unstable"
];

// Track when the page was loaded
const pageLoadTime = Date.now();
const initialPeriodDuration = 180000; // 180 seconds in milliseconds

// Keep track of which initial message to show next
let initialMessageIndex = 0;

// Array of interaction-specific messages
const interactionMessages = [
    "Noise power increased",
    "Impedence value maximized",
    "Spatial audio activated",
    "User interaction successful",
    "Sonic mapping confirmed",
    "Audio pathway opened",
    "Sound source identified",
    "Distortion amplified",
    "Audio sequence initiated"
];

function showRandomChatMessage() {
    // Determine which message set to use based on elapsed time
    const currentTime = Date.now();
    const useInitialMessages = (currentTime - pageLoadTime < initialPeriodDuration);
    
    // Get the message text - sequential for initial period, random for later
    let messageText;
    if (useInitialMessages) {
        // Get the next message in sequence
        messageText = initialNoiseMessages[initialMessageIndex];
        
        // Increment the index for next time, loop back to beginning if needed
        initialMessageIndex = (initialMessageIndex + 1) % initialNoiseMessages.length;
    } else {
        // Randomly select from later messages
        const messageIndex = Math.floor(Math.random() * laterNoiseMessages.length);
        messageText = laterNoiseMessages[messageIndex];
    }
    
    // Create a new message element
    const messageElement = document.createElement('div');
    messageElement.style.backgroundColor = 'rgba(40, 40, 40, 0.8)';
    messageElement.style.color = '#ffffff';
    messageElement.style.borderRadius = '8px';
    messageElement.style.padding = '10px';
    messageElement.style.marginBottom = '10px';
    messageElement.style.maxWidth = '85%';
    messageElement.style.marginLeft = 'auto'; // Align to the right
    messageElement.style.wordWrap = 'break-word';
    messageElement.style.position = 'relative';
    messageElement.style.opacity = '0';
    messageElement.style.transform = 'translateY(20px)';
    messageElement.style.transition = 'opacity 0.3s ease, transform 0.3s ease';
    messageElement.style.borderLeft = '3px solid #555555'; // Neutral border for random messages
    
    // Add a typing indicator that will be shown before the message
    const typingIndicator = document.createElement('div');
    typingIndicator.style.padding = '10px';
    typingIndicator.style.marginBottom = '10px';
    typingIndicator.style.borderRadius = '8px';
    typingIndicator.style.backgroundColor = 'rgba(40, 40, 40, 0.8)';
    typingIndicator.style.color = '#ffffff';
    typingIndicator.style.marginLeft = 'auto';
    typingIndicator.style.width = '60px';
    typingIndicator.style.borderLeft = '3px solid #555555'; // Match the message border
    typingIndicator.innerHTML = '<span style="display: inline-block; animation: typing 1s infinite">...</span>';
    typingIndicator.style.textAlign = 'center';
    
    // Create style for typing animation if it doesn't exist
    if (!document.querySelector('#typing-animation')) {
        const style = document.createElement('style');
        style.id = 'typing-animation';
        style.textContent = `
            @keyframes typing {
                0% { opacity: 0.3; }
                50% { opacity: 1; }
                100% { opacity: 0.3; }
            }
        `;
        document.head.appendChild(style);
    }
    
    // Generate random points for the message
    const randomPoints = Math.floor(Math.random() * 100) + 1;
    
    // Message text is already selected based on the sequential/random logic above
    
    // Add points to the end of the message
    const fullMessage = `${messageText} <span style="color: #aaaaaa">+${randomPoints} noise</span>`;
    
    // Add the typing indicator first
    chatContainer.appendChild(typingIndicator);
    
    // Scroll to the bottom
    chatContainer.scrollTop = chatContainer.scrollHeight;
    
    // After showing typing indicator, show the actual message
    setTimeout(() => {
        // Remove the typing indicator
        typingIndicator.remove();
        
        // Set the message content
        messageElement.innerHTML = fullMessage;
        
        // Add a small label for random messages
        const label = document.createElement('div');
        label.style.position = 'absolute';
        label.style.top = '-8px';
        label.style.right = '10px';
        label.style.fontSize = '10px';
        label.style.color = '#888888';
        label.style.backgroundColor = 'rgba(20, 20, 20, 0.8)';
        label.style.padding = '2px 6px';
        label.style.borderRadius = '4px';
        label.textContent = 'BACKGROUND';
    //    messageElement.appendChild(label);
        
        // Add the message to the container
        chatContainer.appendChild(messageElement);
        
        // Trigger animation
        setTimeout(() => {
            messageElement.style.opacity = '1';
            messageElement.style.transform = 'translateY(0)';
        }, 10);
        
        // Scroll to the bottom again
        chatContainer.scrollTop = chatContainer.scrollHeight;
        
        // Add a timestamp after a short delay
        setTimeout(() => {
            const timestamp = document.createElement('div');
            timestamp.style.fontSize = '10px';
            timestamp.style.color = '#aaaaaa';
            timestamp.style.textAlign = 'right';
            timestamp.style.marginTop = '5px';
            
            // Get current time
            const now = new Date();
            const hours = now.getHours().toString().padStart(2, '0');
            const minutes = now.getMinutes().toString().padStart(2, '0');
            timestamp.textContent = `${hours}:${minutes}`;
            
            messageElement.appendChild(timestamp);
        }, 300);
        
        // Sometimes add a glitch effect to the message
        if (Math.random() > 0.5) {
            setTimeout(() => {
                // Create a glitch effect by briefly changing the text
                const originalHTML = messageElement.innerHTML;
                
                // Generate glitched version of the text
                const glitched = originalHTML.replace(/[a-zA-Z]/g, (char) => {
                    return Math.random() > 0.7 ? String.fromCharCode(Math.random() > 0.5 ? 48 + Math.floor(Math.random() * 10) : 33 + Math.floor(Math.random() * 14)) : char;
                });
                
                // Apply glitch briefly
                messageElement.innerHTML = glitched;
                
                // Restore original after short delay
                setTimeout(() => {
                    messageElement.innerHTML = originalHTML;
                }, 200);
            }, 800);
        }
    }, 1500); // Show typing for 1.5 seconds
}

// Function to show interaction-triggered chat message
function showInteractionChatMessage() {
    // Create a new message element with distinct styling
    const messageElement = document.createElement('div');
    messageElement.style.backgroundColor = 'rgba(20, 60, 80, 0.9)'; // Different background color
    messageElement.style.color = '#ffffff';
    messageElement.style.borderRadius = '8px';
    messageElement.style.padding = '10px';
    messageElement.style.marginBottom = '10px';
    messageElement.style.maxWidth = '85%';
    messageElement.style.marginLeft = 'auto'; // Align to the right
    messageElement.style.wordWrap = 'break-word';
    messageElement.style.position = 'relative';
    messageElement.style.opacity = '0';
    messageElement.style.transform = 'translateY(20px)';
    messageElement.style.transition = 'opacity 0.3s ease, transform 0.3s ease';
    messageElement.style.borderLeft = '3px solid #00aaff'; // Blue border for interaction messages
    
    // Add a typing indicator with a different style
    const typingIndicator = document.createElement('div');
    typingIndicator.style.padding = '10px';
    typingIndicator.style.marginBottom = '10px';
    typingIndicator.style.borderRadius = '8px';
    typingIndicator.style.backgroundColor = 'rgba(20, 60, 80, 0.9)';
    typingIndicator.style.color = '#ffffff';
    typingIndicator.style.marginLeft = 'auto';
    typingIndicator.style.width = '60px';
    typingIndicator.style.borderLeft = '3px solid #00aaff'; // Match the message border
    typingIndicator.innerHTML = '<span style="display: inline-block; animation: typing 0.6s infinite">...</span>';
    typingIndicator.style.textAlign = 'center';
    
    // Create style for typing animation if it doesn't exist
    if (!document.querySelector('#typing-animation')) {
        const style = document.createElement('style');
        style.id = 'typing-animation';
        style.textContent = `
            @keyframes typing {
                0% { opacity: 0.3; }
                50% { opacity: 1; }
                100% { opacity: 0.3; }
            }
        `;
        document.head.appendChild(style);
    }
    
    // Generate random points for the message - higher for interactions
    const interactionPoints = Math.floor(Math.random() * 500) + 100;
    
    // Select a random message from the interaction array
    const messageIndex = Math.floor(Math.random() * interactionMessages.length);
    const messageText = interactionMessages[messageIndex];
    
    // Add points to the end of the message with enhanced styling
    const fullMessage = `${messageText} <span style="color: #00ffaa; font-weight: bold">+${interactionPoints} noise!</span>`;
    
    // Add the typing indicator first
    chatContainer.appendChild(typingIndicator);
    
    // Scroll to the bottom
    chatContainer.scrollTop = chatContainer.scrollHeight;
    
    // After showing typing indicator, show the actual message
    setTimeout(() => {
        // Remove the typing indicator
        typingIndicator.remove();
        
        // Set the message content
        messageElement.innerHTML = fullMessage;
        
        // Add a distinct label for interaction messages
        const label = document.createElement('div');
        label.style.position = 'absolute';
        label.style.top = '-8px';
        label.style.right = '10px';
        label.style.fontSize = '10px';
        label.style.color = '#ffffff';
        label.style.backgroundColor = 'rgba(0, 100, 200, 0.9)';
        label.style.padding = '2px 6px';
        label.style.borderRadius = '4px';
        label.textContent = 'SYSTEM';
        messageElement.appendChild(label);
        
        // Add the message to the container
        chatContainer.appendChild(messageElement);
        
        // Add a pulsing glow effect to the message
        messageElement.style.animation = 'pulse 2s ease-in-out';
        messageElement.style.boxShadow = '0 0 10px rgba(0, 170, 255, 0.5)';
        
        // Create style for pulse animation if it doesn't exist
        if (!document.querySelector('#pulse-animation')) {
            const style = document.createElement('style');
            style.id = 'pulse-animation';
            style.textContent = `
                @keyframes pulse {
                    0% { box-shadow: 0 0 5px rgba(0, 170, 255, 0.5); }
                    50% { box-shadow: 0 0 15px rgba(0, 170, 255, 0.8); }
                    100% { box-shadow: 0 0 5px rgba(0, 170, 255, 0.5); }
                }
            `;
            document.head.appendChild(style);
        }
        
        // Trigger animation
        setTimeout(() => {
            messageElement.style.opacity = '1';
            messageElement.style.transform = 'translateY(0)';
        }, 10);
        
        // Scroll to the bottom again
        chatContainer.scrollTop = chatContainer.scrollHeight;
        
        // Add a timestamp after a short delay
        setTimeout(() => {
            const timestamp = document.createElement('div');
            timestamp.style.fontSize = '10px';
            timestamp.style.color = '#00ccff';
            timestamp.style.textAlign = 'right';
            timestamp.style.marginTop = '5px';
            
            // Get current time
            const now = new Date();
            const hours = now.getHours().toString().padStart(2, '0');
            const minutes = now.getMinutes().toString().padStart(2, '0');
            const seconds = now.getSeconds().toString().padStart(2, '0');
            timestamp.textContent = `${hours}:${minutes}:${seconds}`;
            
            messageElement.appendChild(timestamp);
        }, 300);
        
        // Add a more pronounced glitch effect
        setTimeout(() => {
            // Create a series of glitches for a more dramatic effect
            const originalHTML = messageElement.innerHTML;
            const glitchCount = 3;
            
            for (let i = 0; i < glitchCount; i++) {
                setTimeout(() => {
                    // Generate heavily glitched version
                    const glitched = originalHTML.replace(/[a-zA-Z0-9]/g, (char) => {
                        return Math.random() > 0.3 ? String.fromCharCode(33 + Math.floor(Math.random() * 93)) : char;
                    });
                    
                    // Apply glitch
                    messageElement.innerHTML = glitched;
                    
                    // Restore after brief interval
                    setTimeout(() => {
                        messageElement.innerHTML = originalHTML;
                    }, 100);
                }, i * 300); // Stagger the glitches
            }
        }, 800);
    }, 1000); // Show typing for 1 second
}

// Function to show the stop message
function showStopMessageAnimation() {
    // Create a special error message
    const errorMessage = document.createElement('div');
    errorMessage.style.backgroundColor = 'rgba(80, 0, 0, 0.8)';
    errorMessage.style.color = '#ff5555';
    errorMessage.style.borderRadius = '8px';
    errorMessage.style.padding = '10px';
    errorMessage.style.marginBottom = '10px';
    errorMessage.style.width = '85%';
    errorMessage.style.marginLeft = 'auto';
    errorMessage.style.wordWrap = 'break-word';
    errorMessage.style.fontWeight = 'bold';
    errorMessage.style.opacity = '0';
    errorMessage.style.transform = 'translateY(20px)';
    errorMessage.style.transition = 'opacity 0.3s ease, transform 0.3s ease';
    errorMessage.innerHTML = 'CONNECTION TERMINATED 😭';
    
    // Add the message to the container
    chatContainer.appendChild(errorMessage);
    
    // Trigger animation
    setTimeout(() => {
        errorMessage.style.opacity = '1';
        errorMessage.style.transform = 'translateY(0)';
        
        // Add shake effect
        errorMessage.style.animation = 'shake 0.5s ease-in-out';
        
        // Create style for shake animation if it doesn't exist
        if (!document.querySelector('#shake-animation')) {
            const style = document.createElement('style');
            style.id = 'shake-animation';
            style.textContent = `
                @keyframes shake {
                    0%, 100% { transform: translateX(0); }
                    10%, 30%, 50%, 70%, 90% { transform: translateX(-5px); }
                    20%, 40%, 60%, 80% { transform: translateX(5px); }
                }
            `;
            document.head.appendChild(style);
        }
    }, 10);
    
    // Scroll to the bottom
    chatContainer.scrollTop = chatContainer.scrollHeight;
}

// Start showing messages automatically
function startRandomChatMessages() {
    // Show first message after 8 seconds
    setTimeout(() => {
        showRandomChatMessage();
        
        // Then start showing messages periodically
        setInterval(() => {
            // 70% chance to show a message each time
            if (Math.random() < 0.7) {
                showRandomChatMessage();
            }
        }, 10000 + Math.random() * 15000); // Random interval between 10-25 seconds
    }, 8000);
}

function scheduleRandomMessages() {
    setInterval(() => {
        if (Math.random() < 0.5) { // 50% chance to show message
            showRandomChatMessage();
        }
    }, 15000); // Every 15 seconds
}
scheduleRandomMessages();

// Create or use existing speed meter
const speedMeter = document.getElementById('speed-meter') || document.createElement('div');
speedMeter.id = 'speed-meter';
speedMeter.style.position = 'fixed';
speedMeter.style.bottom = '1rem';
speedMeter.style.left = '1rem';
speedMeter.style.backgroundColor = 'rgba(0, 0, 0, 0.6)';
speedMeter.style.color = '#ffffff';
speedMeter.style.padding = '0.5rem 1rem';
speedMeter.style.borderRadius = '0.5rem';
speedMeter.style.fontFamily = 'monospace';
speedMeter.style.fontSize = '.75rem';
speedMeter.style.display = 'flex';
speedMeter.style.alignItems = 'center';
speedMeter.style.zIndex = '1000';
speedMeter.innerHTML = `
  <span>NOISE: </span>
  <div style="margin-left: 0.5rem; width: 200px; height: 20px; background-color: rgba(50, 50, 50, 0.7); 
       border-radius: 10px; overflow: hidden; position: relative;">
    <div id="speed-marker" style="position: absolute; left: 50%; top: 0; height: 100%; width: 2px; background-color: #ffffff; z-index: 2;"></div>
    <div id="speed-fill-negative" style="position: absolute; right: 50%; top: 0; height: 100%; width: 0%; background-color: #ff6633; 
         transition: width 0.15s ease, background-color 0.2s ease;"></div>
    <div id="speed-fill-positive" style="position: absolute; left: 50%; top: 0; height: 100%; width: 0%; background-color: #00aaff; 
         transition: width 0.15s ease, background-color 0.2s ease;"></div>
    <!-- Removed numerical display -->
  </div>
`;

// Make sure it's in the DOM
if (!document.getElementById('speed-meter')) {
  document.body.appendChild(speedMeter);
}

// Function to update the speed meter with light smoothing
function updateSpeedMeter(speed) {
  // Get the DOM elements
  const speedFillNegative = document.getElementById('speed-fill-negative');
  const speedFillPositive = document.getElementById('speed-fill-positive');
  
  if (!speedFillNegative || !speedFillPositive) return; // Ensure elements exist
  
  // Maximum speed for scaling the meter (can be adjusted)
  const maxSpeed = 300;
  
  // We'll use the raw speed value to ensure it's responsive
  const smoothedSpeed = speed;
  
  // Calculate percentage for display (0-50%)
  const percentage = Math.min(50, Math.abs(smoothedSpeed) / maxSpeed * 50);
  
  // Update the appropriate fill based on direction
  if (smoothedSpeed < 0) {
    // Negative speed - fill left side
    speedFillNegative.style.width = percentage + '%';
    speedFillPositive.style.width = '0%';
    
    // Color based on magnitude (red spectrum)
    const absSpeed = Math.abs(smoothedSpeed);
    if (absSpeed > 200) {
      speedFillNegative.style.backgroundColor = '#ff3333'; // Deep red for high backward speed
    } else if (absSpeed > 100) {
      speedFillNegative.style.backgroundColor = '#ff6633'; // Orange-red for medium backward speed
    } else {
      speedFillNegative.style.backgroundColor = '#ff9933'; // Orange for slow backward speed
    }
  } else if (smoothedSpeed > 0) {
    // Positive speed - fill right side
    speedFillPositive.style.width = percentage + '%';
    speedFillNegative.style.width = '0%';
    
    // Color based on magnitude (blue spectrum)
    if (smoothedSpeed > 200) {
      speedFillPositive.style.backgroundColor = '#0066ff'; // Deep blue for high forward speed
    } else if (smoothedSpeed > 100) {
      speedFillPositive.style.backgroundColor = '#00aaff'; // Medium blue for medium forward speed
    } else {
      speedFillPositive.style.backgroundColor = '#00ddff'; // Light blue for slow forward speed
    }
  } else {
    // Speed is exactly zero
    speedFillNegative.style.width = '0%';
    speedFillPositive.style.width = '0%';
  }
  
}

// Function to show/hide the speed meter
function toggleSpeedMeter(visible = true) {
  const meter = document.getElementById('speed-meter');
  if (meter) {
    meter.style.display = visible ? 'flex' : 'none';
  }
}


  //Gamepad setup
  function handleGamepadInput() {
    const gamepads = navigator.getGamepads();
    const gp = gamepads[0]; // Assuming a single gamepad

    if (gp) {
        const leftStickX = gp.axes[0]; // Left stick horizontal
        const leftStickY = gp.axes[1]; // Left stick vertical
        const rightStickX = gp.axes[2]; // Right stick horizontal
        const rightStickY = gp.axes[3]; // Right stick vertical

        const moveSpeed = 0; // Adjust for movement control
        const lookSpeed = 20; // Sensitivity for mouse movement

        // Move camera forward/backward
        if (Math.abs(leftStickY) > 0.1) {
            controls.moveForward(-leftStickY * moveSpeed);
        }
        // Move camera left/right
        if (Math.abs(leftStickX) > 0.1) {
            controls.moveRight(leftStickX * moveSpeed);
        }

        // Simulate mouse movement using right stick
        if (Math.abs(rightStickX) > 0.1 || Math.abs(rightStickY) > 0.1) {
            const mouseMoveEvent = new MouseEvent("mousemove", {
                movementX: rightStickX * lookSpeed,
                movementY: rightStickY * lookSpeed
            });
            document.dispatchEvent(mouseMoveEvent);
        }
    }
}

//End of gamepad setup

let speed = 0; // Movement speed
let rms = 0;
const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));

// Microphone Input and Analysis Code
async function setupAudioInput() {
    try {
        console.log("Setting up enhanced microphone analysis...");
        
        // Create a separate audio context for microphone analysis to avoid interfering with the 4-channel output
        const micAudioContext = new (window.AudioContext || window.webkitAudioContext)();
        
        // Request microphone access with high-quality settings
        const micStream = await navigator.mediaDevices.getUserMedia({
            audio: {
                echoCancellation: false,
                noiseSuppression: false,
                autoGainControl: false,
                sampleRate: { ideal: 48000 }
            }
        });
        
        console.log("Microphone access granted");
        
        // Create microphone source
        const micSource = micAudioContext.createMediaStreamSource(micStream);
        
        // Create analyzer for frequency and time-domain analysis
        const analyzer = micAudioContext.createAnalyser();
        analyzer.fftSize = 2048; // Higher value for more detailed frequency analysis
        const bufferLength = analyzer.frequencyBinCount;
        
        // Create data arrays for different types of analysis
        const timeDataArray = new Float32Array(analyzer.fftSize);
        const frequencyDataArray = new Float32Array(bufferLength);
        const previousFrequencies = new Float32Array(bufferLength);
        
        // Connect microphone to analyzer
        micSource.connect(analyzer);
        
        // Analysis parameters
        const speedFactor = .95;
      //  const AMPLITUDE_THRESHOLD = 0.001;
      const AMPLITUDE_THRESHOLD = 0.001;
        let targetSpeed = 0;
        
        // Store references in the global scope
        window.microphoneInput = {
            context: micAudioContext,
            stream: micStream,
            source: micSource,
            analyzer: analyzer,
            timeDataArray: timeDataArray,
            frequencyDataArray: frequencyDataArray,
            previousFrequencies: previousFrequencies,
            bufferLength: bufferLength,
            isAnalyzing: true,
            speedFactor: speedFactor,
            amplitudeThreshold: AMPLITUDE_THRESHOLD,
            targetSpeed: targetSpeed
        };
        
        // Start analysis loop
        analyzeAudio();
        
        console.log("Enhanced microphone analysis started");
        return true;
    } catch (error) {
        console.error("Error setting up microphone:", error.message);
        return false;
    }
}

// Spectral analysis functions
function calculateSpectralCentroid(frequencyData, sampleRate, bufferLength) {
    let numerator = 0;
    let denominator = 0;
    for (let i = 0; i < frequencyData.length; i++) {
        const frequency = i * sampleRate / (2 * bufferLength);
        const magnitude = Math.abs(frequencyData[i]);
        numerator += frequency * magnitude;
        denominator += magnitude;
    }
    return denominator !== 0 ? numerator / denominator : 0;
}

function calculateSpectralSpread(frequencyData, centroid, sampleRate, bufferLength) {
    let numerator = 0;
    let denominator = 0;
    for (let i = 0; i < frequencyData.length; i++) {
        const frequency = i * sampleRate / (2 * bufferLength);
        const magnitude = Math.abs(frequencyData[i]);
        numerator += magnitude * Math.pow(frequency - centroid, 2);
        denominator += magnitude;
    }
    return denominator !== 0 ? Math.sqrt(numerator / denominator) : 0;
}

function calculateSpectralKurtosis(frequencyData, centroid, spread, sampleRate, bufferLength) {
    let numerator = 0, denominator = 0;
    for (let i = 0; i < frequencyData.length; i++) {
        const frequency = i * sampleRate / (2 * bufferLength);
        const magnitude = Math.abs(frequencyData[i]);
        // Check for valid spread to avoid division by zero
        if (spread > 0) {
            numerator += magnitude * Math.pow((frequency - centroid) / spread, 4);
            denominator += magnitude;
        }
    }
    return denominator !== 0 && spread > 0 ? (numerator / denominator) - 3 : 0; // Subtract 3 to center at zero
}

function calculateSpectralFlux(currentFrequencies, previousFrequencies) {
    let sum = 0;
    for (let i = 0; i < currentFrequencies.length; i++) {
        const diff = currentFrequencies[i] - previousFrequencies[i];
        sum += diff * diff;
    }
    return Math.sqrt(sum) / currentFrequencies.length;
}

// Main audio analysis function
function analyzeAudio() {
    if (!window.microphoneInput || !window.microphoneInput.isAnalyzing) return;
    
    const { 
        analyzer, timeDataArray, frequencyDataArray, previousFrequencies, 
        bufferLength, context, amplitudeThreshold, speedFactor
    } = window.microphoneInput;
    
    // Get time domain data for RMS calculation
    analyzer.getFloatTimeDomainData(timeDataArray);
    
    // Calculate RMS (audio volume)
    let sumSquares = 0;
    for (let i = 0; i < timeDataArray.length; i++) {
        sumSquares += timeDataArray[i] * timeDataArray[i];
    }
    const rms = Math.sqrt(sumSquares / timeDataArray.length);
    
    // Only perform detailed analysis if sound is above threshold
    if (rms >= amplitudeThreshold) {
        // Get frequency data
        analyzer.getFloatFrequencyData(frequencyDataArray);
        
        // Convert from dB to linear scale
        const linearFrequencies = frequencyDataArray.map(db => Math.pow(10, db / 20));
        
        // Perform spectral analysis
        const centroid = calculateSpectralCentroid(linearFrequencies, context.sampleRate, bufferLength);
        const spread = calculateSpectralSpread(linearFrequencies, centroid, context.sampleRate, bufferLength);
        const flux = calculateSpectralFlux(linearFrequencies, previousFrequencies);
        const kurtosis = calculateSpectralKurtosis(linearFrequencies, centroid, spread, context.sampleRate, bufferLength);
        
        // Log detailed analysis to console
        console.log(`Audio Analysis: RMS=${rms.toFixed(5)}, Centroid=${centroid.toFixed(2)}Hz, Spread=${spread.toFixed(2)}, Flux=${flux.toFixed(7)}, Kurtosis=${kurtosis.toFixed(2)}`);
        
        // Set movement speed based on audio characteristics
        if (centroid > 0) {
            // Calculate target speed using the formula
            window.microphoneInput.targetSpeed = 5 * (((spread - 2500) / 50) + (flux * 10000000) - (kurtosis * 2)) + 30; // good for breath & air noise & key clicks

            // window.microphoneInput.targetSpeed = 3 * (((spread - 2500) / 50) + (flux * 10000000) - (kurtosis * 2)) + 30; // good for breath & air noise & key clicks
          //  window.microphoneInput.targetSpeed = 4 * (((spread - 2500) / 50) + (flux * 10000000) - (kurtosis * 2)) + 300; // good for multiphonics

            // Log target speed
            console.log(`Target Speed: ${window.microphoneInput.targetSpeed.toFixed(2)}`);
        }
        
        // Save current frequencies for next flux calculation
        previousFrequencies.set(linearFrequencies);
    } else {
        // Reset target speed when audio is below threshold
        window.microphoneInput.targetSpeed = 0;
    }
    
    // Gradually adjust speed for smoother movement
    if (typeof speed !== 'undefined') {
        speed += (window.microphoneInput.targetSpeed - speed) * speedFactor;
    } else {
        // If speed variable doesn't exist in global scope, create it
        window.speed = 0;
        speed += (window.microphoneInput.targetSpeed - speed) * speedFactor;
    }
    
    // Continue analysis loop
    requestAnimationFrame(analyzeAudio);
}

// Function to stop microphone input and analysis
function stopMicrophoneInput() {
    if (window.microphoneInput) {
        console.log("Stopping microphone input...");
        
        // Stop analysis
        window.microphoneInput.isAnalyzing = false;
        
        // Stop audio tracks
        if (window.microphoneInput.stream) {
            window.microphoneInput.stream.getTracks().forEach(track => track.stop());
        }
        
        // Close audio context
        if (window.microphoneInput.context && window.microphoneInput.context.state !== 'closed') {
            window.microphoneInput.context.close();
        }
        
        // Clear references
        window.microphoneInput = null;
        
        console.log("Microphone input stopped");
        return true;
    }
    return false;
}

// Add a function to toggle microphone input
function toggleMicrophoneInput() {
    if (window.microphoneInput) {
        return stopMicrophoneInput();
    } else {
        return setupAudioInput();
    }
}
   
function animate() {
    updateAudioGains();
    updateSecondAudioGains();
    updateThirdAudioGains();
    const delta = clock.getDelta();
    handleGamepadInput();
  
    // Update iframe visibility
    if (window.iframeLoaders) {
        window.iframeLoaders.forEach(loader => {
            loader.updateVisibility(camera);
        });
    }
  
    if (isPointerLocked) {
       move.forward = true; // Comment out for DEVELOPMENT
    }
    
    if (mixer) {
        mixer.update(delta);
    }
  
    if (firstBellMixer) {
        firstBellMixer.update(delta);
    }

     if (mixer2) {
        mixer2.update(delta);
    }

    if (mixer3) {
        mixer3.update(delta);
    }

    if (mixer4) {
        mixer4.update(delta);
    }

    if (mixer5) {
        mixer5.update(delta);
    }
  
    const baseMoveSpeed = 1; // Base speed multiplier
    const maxSpeed = 800
    const minSpeed = -800;
    const clampedSpeed = Math.max(minSpeed, Math.min(speed, maxSpeed));
    const adjustedSpeed = clampedSpeed * delta * baseMoveSpeed; // for performance
  //  const adjustedSpeed = 200 * delta; // for DEVELOPMENT

    updateSpeedMeter(adjustedSpeed / delta, 800); // Display raw speed value

  
    // Store initial position
    const initialPosition = camera.position.clone();
    let finalPosition = initialPosition.clone();
    
    // Calculate the movement vector
    const moveVector = new THREE.Vector3(0, 0, 0);
    
    // Get the camera's forward and right vectors
    const forward = new THREE.Vector3();
    const right = new THREE.Vector3();
    controls.getDirection(forward);
    right.crossVectors(forward, new THREE.Vector3(0, 1, 0));
    
    // Normalize vectors to handle diagonal movement correctly
    forward.normalize();
    right.normalize();
    
    // Add movement components
    if (move.forward) moveVector.add(forward.multiplyScalar(adjustedSpeed));
    if (move.backward) moveVector.sub(forward.multiplyScalar(adjustedSpeed));
    if (move.left) moveVector.sub(right.multiplyScalar(adjustedSpeed));
    if (move.right) moveVector.add(right.multiplyScalar(adjustedSpeed));
    
    // Test moving along both axes separately
    if (moveVector.length() > 0) {
        // Try X movement
        const xMovement = new THREE.Vector3(moveVector.x, 0, 0);
        camera.position.add(xMovement);
        updateBoundingBoxes();

    const hitBox13 = cameraBoundingBox.intersectsBox(boundingBox13);
    const hitBox14 = cameraBoundingBox.intersectsBox(boundingBox14);
    const hitBox15 = cameraBoundingBox.intersectsBox(boundingBox15);

     // Track the bell animation state
    if (!window.bellAnimationState) {
    window.bellAnimationState = {
        isPlaying: true,   // Track if animation is currently playing
        hasCollided: false, // Track if user is currently colliding with bell
        canToggle: true,    // Track if we can perform another toggle action
        actions: null       // Store paused actions
    };
    }

    // Handle bell interaction when collision happens
    if (hitBox13) {
  // Only toggle state when entering the collision zone
  if (!window.bellAnimationState.hasCollided && window.bellAnimationState.canToggle) {
    if (firstBellMixer) {
      // Toggle between play/stop
      if (window.bellAnimationState.isPlaying) {
        // Pause the bell animation
        console.log("Camera collided with bell - pausing animation and audio");
        
        // Always recreate the actions array to fix the issue after first pause/resume
        window.bellAnimationState.actions = [];
        
        // Save the state of all active actions
        firstBellMixer._actions.forEach(action => {
          if (action.isRunning() || action.timeScale !== 0) {
            window.bellAnimationState.actions.push({
              action: action,
              time: action.time,
              timeScale: action.getEffectiveTimeScale()
            });
            
            // Pause by setting timeScale to 0 
            action.timeScale = 0;
          }
        });
        
        // Pause the spatial audio with fade out
        if (window.audioState && window.audioState.isPlaying) {
          const fadeTime = 0.2; // 200ms fade out
          
          // Calculate the current playback position accurately
          const elapsedTime = audioContext.currentTime - window.audioState.lastStartTime;
          window.audioState.playbackOffset = (window.audioState.playbackOffset + elapsedTime) % window.audioState.duration;
          
          // Reduce all channel gains smoothly
          const currentTime = audioContext.currentTime;
          channelGains.forEach(gainNode => {
            const currentGain = gainNode.gain.value;
            gainNode.gain.setValueAtTime(currentGain, currentTime);
            gainNode.gain.linearRampToValueAtTime(0, currentTime + fadeTime);
          });
          
          // Schedule stopping the source after fade completes
          setTimeout(() => {
            if (window.audioState.currentSource) {
              try {
                window.audioState.currentSource.stop();
              } catch (e) {
                console.log("Error stopping audio source:", e);
              }
            }
            window.audioState.isPlaying = false;
          }, fadeTime * 1000);
          
          console.log("Audio paused at offset:", window.audioState.playbackOffset.toFixed(3), "seconds");
        }
        
        window.bellAnimationState.isPlaying = false;
        showStopMessageAnimation();
      } else {
        // Resume the animation from its current position
        console.log("Camera collided with bell - resuming animation and audio");
        
        // If we have stored actions, restore them
        if (window.bellAnimationState.actions && window.bellAnimationState.actions.length > 0) {
          window.bellAnimationState.actions.forEach(savedAction => {
            // Restore the original timeScale to resume animation
            savedAction.action.timeScale = savedAction.timeScale || 1;
          });
        } else {
          // Fallback in case there are no saved actions
          firstBellMixer._actions.forEach(action => {
            action.timeScale = 1;
            if (!action.isRunning()) {
              action.play();
            }
          });
        }
        
        // Resume the spatial audio with fade in
        if (window.audioState) {
          const fadeTime = 0.1; // 100ms fade in
          
          // Create a new buffer source with the same connections as original
          const newSourceNode = audioContext.createBufferSource();
          newSourceNode.buffer = window.audioState.buffer;
          newSourceNode.loop = true;
          
          // Get number of channels in the buffer
          const numChannels = window.audioState.buffer.numberOfChannels;
          
          // Connect to channel gains based on channel count
          if (numChannels === 1) {
            // Mono source - connect to all gain nodes
            for (let i = 0; i < channelGains.length; i++) {
              newSourceNode.connect(channelGains[i]);
            }
          } else if (numChannels === 2) {
            // Stereo source - use splitter
            const splitter = audioContext.createChannelSplitter(2);
            newSourceNode.connect(splitter);
            
            if (isQuadSupported) {
              // Quad mode connections
              splitter.connect(channelGains[0], 0); // Left to front-left
              splitter.connect(channelGains[2], 0); // Left to back-left
              splitter.connect(channelGains[1], 1); // Right to front-right
              splitter.connect(channelGains[3], 1); // Right to back-right
            } else {
              // Stereo mode connections
              splitter.connect(channelGains[0], 0); // Left to left
              splitter.connect(channelGains[1], 1); // Right to right
            }
          }
          
          // Start from the stored offset position
          newSourceNode.start(0, window.audioState.playbackOffset);
          window.audioState.lastStartTime = audioContext.currentTime;
          window.audioState.currentSource = newSourceNode;
          window.audioState.isPlaying = true;
          
          // Calculate the position gains now
          const posGains = calculateChannelGains(
            camera.position,
            soundSourcePosition,
            controls
          );
          
          // Fade in each channel gain with the appropriate spatial balance
          const currentTime = audioContext.currentTime;
          
          if (isQuadSupported) {
            // Quad mode - fade in each channel with proper spatial value
            for (let i = 0; i < channelGains.length; i++) {
              channelGains[i].gain.setValueAtTime(0, currentTime);
              channelGains[i].gain.linearRampToValueAtTime(posGains[i], currentTime + fadeTime);
            }
          } else {
            // Stereo mode - downmix and fade in
            channelGains[0].gain.setValueAtTime(0, currentTime);
            channelGains[0].gain.linearRampToValueAtTime(
              posGains[0] + posGains[2], // mix front-left and back-left
              currentTime + fadeTime
            );
            
            channelGains[1].gain.setValueAtTime(0, currentTime);
            channelGains[1].gain.linearRampToValueAtTime(
              posGains[1] + posGains[3], // mix front-right and back-right
              currentTime + fadeTime
            );
          }
          
          console.log("Audio resumed from offset:", window.audioState.playbackOffset.toFixed(3), "seconds");
        }
        
        window.bellAnimationState.isPlaying = true;
        showInteractionChatMessage();

      }
      
      // Prevent multiple toggles while inside collision zone
      window.bellAnimationState.canToggle = false;
    }
  }
  window.bellAnimationState.hasCollided = true;
} else {
  // When player moves away from the bell, allow toggling again
  if (window.bellAnimationState.hasCollided) {
    window.bellAnimationState.hasCollided = false;
    window.bellAnimationState.canToggle = true;
    console.log("Player exited bell collision zone - ready for next interaction");
  }
}

if (!window.bell3AnimationState) {
    window.bell3AnimationState = {
        isPlaying: false,
        hasCollided: false,
        canToggle: true,
        actions: []
    };
}

// Initialize second audio state tracker if it doesn't exist
if (!window.bell3AnimationState) {
    window.bell3AnimationState = {
        isPlaying: false,
        hasCollided: false,
        canToggle: true,
        actions: []
    };
}

// Initialize second audio state tracker if it doesn't exist
if (!window.secondAudioState) {
    window.secondAudioState = {
        isPlaying: false,
        buffer: secondSourceNode ? secondSourceNode.buffer : null,
        currentSource: null,
        startTime: 0,
        pauseTime: 0,
        offset: 0
    };
}

// Handle bell3 interaction when collision with hitBox14 happens
if (hitBox14) {
    // Only toggle state when entering the collision zone
    if (!window.bell3AnimationState.hasCollided && window.bell3AnimationState.canToggle) {
        if (mixer3) {
            // Toggle between play/stop based on current state
            if (!window.bell3AnimationState.isPlaying) {
                // START THE ANIMATION
                console.log("Camera collided with bell3 - starting animation and audio");
                
                // Handle animation
                mixer3._actions.forEach(action => {
                    action.timeScale = 1;
                    if (!action.isRunning()) {
                        action.play();
                    }
                });
                
                // Handle audio - create a new source node
                if (window.secondAudioState.buffer) {
                    // Create a new source node
                    const newSource = audioContext.createBufferSource();
                    newSource.buffer = window.secondAudioState.buffer;
                    newSource.loop = true;
                    
                    // Store the new source
                    window.secondAudioState.currentSource = newSource;
                    window.secondAudioState.startTime = audioContext.currentTime;
                    
                    // Connect the source to all gain nodes
                    const numChannels = newSource.buffer.numberOfChannels;
                    if (numChannels === 1) {
                        // Mono source - connect to all gain nodes
                        for (let i = 0; i < secondChannelGains.length; i++) {
                            newSource.connect(secondChannelGains[i]);
                        }
                    } else if (numChannels === 2) {
                        // Stereo source - handle based on system capabilities
                        const splitter = audioContext.createChannelSplitter(2);
                        newSource.connect(splitter);
                        
                        if (isQuadSupported) {
                            // Quad mode connections
                            splitter.connect(secondChannelGains[0], 0); // Left to front-left
                            splitter.connect(secondChannelGains[2], 0); // Left to back-left
                            splitter.connect(secondChannelGains[1], 1); // Right to front-right
                            splitter.connect(secondChannelGains[3], 1); // Right to back-right
                        } else {
                            // Stereo mode connections
                            splitter.connect(secondChannelGains[0], 0); // Left to left
                            splitter.connect(secondChannelGains[1], 1); // Right to right
                        }
                    }
                    
                    // Fade in the gain nodes
                    const fadeTime = 0.5; // 500ms fade in
                    const currentTime = audioContext.currentTime;
                    const posGains = calculateSecondChannelGains(
                        camera.position,
                        secondSoundSourcePosition,
                        controls
                    );
                    
                    // Set initial gain to 0 and fade in
                    if (isQuadSupported) {
                        for (let i = 0; i < secondChannelGains.length; i++) {
                            secondChannelGains[i].gain.setValueAtTime(0, currentTime);
                            secondChannelGains[i].gain.linearRampToValueAtTime(posGains[i], currentTime + fadeTime);
                        }
                    } else {
                        // Stereo mode - downmix
                        secondChannelGains[0].gain.setValueAtTime(0, currentTime);
                        secondChannelGains[0].gain.linearRampToValueAtTime(
                            posGains[0] + posGains[2], // mix front-left and back-left
                            currentTime + fadeTime
                        );
                        
                        secondChannelGains[1].gain.setValueAtTime(0, currentTime);
                        secondChannelGains[1].gain.linearRampToValueAtTime(
                            posGains[1] + posGains[3], // mix front-right and back-right
                            currentTime + fadeTime
                        );
                    }
                    
                    // Start playback from the stored offset
                    console.log("Starting audio at offset:", window.secondAudioState.offset);
                    newSource.start(0, window.secondAudioState.offset);
                }
                
                // Update state
                window.bell3AnimationState.isPlaying = true;
                window.secondAudioState.isPlaying = true;
                showInteractionChatMessage();
            } else {
                // STOP THE ANIMATION
                console.log("Camera collided with bell3 - stopping animation and audio");
                
                // Pause animation by setting timeScale to 0
                mixer3._actions.forEach(action => {
                    action.timeScale = 0;
                });
                
                // Calculate and store the current playback position
                if (window.secondAudioState.currentSource && window.secondAudioState.buffer) {
                    const playbackDuration = audioContext.currentTime - window.secondAudioState.startTime;
                    const bufferDuration = window.secondAudioState.buffer.duration;
                    
                    // Calculate the current position in the loop, considering the initial offset
                    window.secondAudioState.offset = (window.secondAudioState.offset + playbackDuration) % bufferDuration;
                    console.log("Pausing audio at offset:", window.secondAudioState.offset);
                    
                    // Fade out audio
                    const fadeTime = 0.5; // 500ms fade out
                    const currentTime = audioContext.currentTime;
                    
                    // Fade out all gain nodes
                    secondChannelGains.forEach(gainNode => {
                        const currentGain = gainNode.gain.value;
                        gainNode.gain.setValueAtTime(currentGain, currentTime);
                        gainNode.gain.linearRampToValueAtTime(0, currentTime + fadeTime);
                    });
                    
                    // Schedule source stop after fade completes
                    setTimeout(() => {
                        try {
                            if (window.secondAudioState.currentSource) {
                                window.secondAudioState.currentSource.stop();
                                window.secondAudioState.currentSource = null;
                            }
                        } catch (e) {
                            console.log("Error stopping audio source:", e);
                        }
                    }, fadeTime * 1000);
                }
                
                // Update state
                window.bell3AnimationState.isPlaying = false;
                window.secondAudioState.isPlaying = false;
                showStopMessageAnimation();
            }
            
            // Prevent multiple toggles while inside collision zone
            window.bell3AnimationState.canToggle = false;
        }
    }
    // Mark that we're inside the collision zone
    window.bell3AnimationState.hasCollided = true;
} else {
    // When player moves away from bell3, allow toggling again
    if (window.bell3AnimationState && window.bell3AnimationState.hasCollided) {
        window.bell3AnimationState.hasCollided = false;
        window.bell3AnimationState.canToggle = true;
        console.log("Player exited bell3 collision zone - ready for next interaction");
    }
}

if (bell2Model) {
        if (cameraBoundingBox.intersectsBox(boundingBox14)) {
            // Add to scene if not already added
            if (!bell2Model.parent) {
                console.log("Adding bell2 to scene - camera entered trigger zone");
                scene.add(bell2Model);
                
                // Optionally show an interaction message
                if (typeof showInteractionChatMessage === 'function') {
                    showInteractionChatMessage();
                }
            }
        } else {
            // Remove from scene if added
            if (bell2Model.parent) {
            //    console.log("Removing bell2 from scene - camera left trigger zone");
           //     scene.remove(bell2Model);
            }
        }
    }
        
        const hitXRed = cameraBoundingBox.intersectsBox(redBoxBoundingBox);
        const hitXGreen = cameraBoundingBox.intersectsBox(greenBoxBoundingBox);
        const hitX3 = cameraBoundingBox.intersectsBox(boundingBox3);
        const hitX4 = cameraBoundingBox.intersectsBox(boundingBox4);
        const hitX5 = cameraBoundingBox.intersectsBox(boundingBox5);
        const hitX6 = cameraBoundingBox.intersectsBox(boundingBox6);
        const hitX7 = cameraBoundingBox.intersectsBox(boundingBox7);
        const hitX8 = cameraBoundingBox.intersectsBox(boundingBox8);
        const hitX9 = cameraBoundingBox.intersectsBox(boundingBox9);
        const hitX10 = cameraBoundingBox.intersectsBox(boundingBox10);
        const hitX11 = cameraBoundingBox.intersectsBox(boundingBox11);
        const hitX12 = cameraBoundingBox.intersectsBox(boundingBox12);
        
        if (hitXRed || hitXGreen || hitX3 || hitX4 || hitX5 || hitX6 || hitX7 || hitX8 || hitX9 || hitX10 || hitX11 || hitX12 ) {
            // Revert X movement if there's a collision
            camera.position.sub(xMovement);
        } else {
            finalPosition.add(xMovement);
        }
        
        //Test Z movement
        const zMovement = new THREE.Vector3(0, 0, moveVector.z);
        camera.position.copy(initialPosition);
        camera.position.add(zMovement);
        updateBoundingBoxes();
        
        const hitZRed = cameraBoundingBox.intersectsBox(redBoxBoundingBox);
        const hitZGreen = cameraBoundingBox.intersectsBox(greenBoxBoundingBox);
        const hitZ3 = cameraBoundingBox.intersectsBox(boundingBox3);
        const hitZ4 = cameraBoundingBox.intersectsBox(boundingBox4);
        const hitZ5 = cameraBoundingBox.intersectsBox(boundingBox5);
        const hitZ6 = cameraBoundingBox.intersectsBox(boundingBox6);
        const hitZ7 = cameraBoundingBox.intersectsBox(boundingBox7);
        const hitZ8 = cameraBoundingBox.intersectsBox(boundingBox8);
        const hitZ9 = cameraBoundingBox.intersectsBox(boundingBox9);
        const hitZ10 = cameraBoundingBox.intersectsBox(boundingBox10);
        const hitZ11 = cameraBoundingBox.intersectsBox(boundingBox11);
        const hitZ12 = cameraBoundingBox.intersectsBox(boundingBox12);
      
        if (hitZRed || hitZGreen || hitZ3 || hitZ4 || hitZ5 || hitZ6 || hitZ7 || hitZ8 || hitZ9 || hitZ10 || hitZ11 || hitZ12 ) {
            // Revert Z movement if there's a collision
            camera.position.sub(zMovement);
        } else {
            finalPosition.add(zMovement);
        }
        
        // Set final position
        camera.position.copy(finalPosition);
        updateBoundingBoxes();
    }
    
    if (resizeRendererToDisplaySize(renderer)) {
        camera.aspect = canvas.clientWidth / canvas.clientHeight;
        camera.updateProjectionMatrix();
    }
    
    updateBoundingBoxes();
      
    renderer.render(scene, camera);
    cssRenderer.render(cssScene, camera);
    requestAnimationFrame(animate);
}
requestAnimationFrame(animate);
    }
    
</script>
</body>
</html>
